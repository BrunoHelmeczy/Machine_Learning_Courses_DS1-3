<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Bruno Helmeczy" />

<meta name="date" content="2021-11-04" />

<title>Data Science In-Class Kaggle Competition Report</title>

<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

/* A workaround for https://github.com/jgm/pandoc/issues/4278 */
a.sourceLine {
  pointer-events: auto;
}

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">@font-face{font-family:"Open Sans";font-style:normal;font-weight:400;src:local("Open Sans"),local("OpenSans"),url(data:application/font-woff;base64,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) format("woff")}@font-face{font-family:"Open Sans";font-style:normal;font-weight:700;src:local("Open Sans Bold"),local("OpenSans-Bold"),url(data:application/font-woff;base64,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) format("woff")}*{box-sizing:border-box}body{padding:0;margin:0;font-family:"Open Sans","Helvetica Neue",Helvetica,Arial,sans-serif;font-size:16px;line-height:1.5;color:#606c71}a{color:#1e6bb8;text-decoration:none}a:hover{text-decoration:underline}.page-header{color:#fff;text-align:center;background-color:#159957;background-image:linear-gradient(120deg,#155799,#159957);padding:1.5rem 2rem}.page-header :last-child{margin-bottom:.5rem}@media screen and (max-width:42em){.page-header{padding:1rem 1rem}}.project-name{margin-top:0;margin-bottom:.1rem;font-size:2rem}@media screen and (max-width:42em){.project-name{font-size:1.75rem}}.project-tagline{margin-bottom:2rem;font-weight:400;opacity:.7;font-size:1.5rem}@media screen and (max-width:42em){.project-tagline{font-size:1.2rem}}.project-author,.project-date{font-weight:400;opacity:.7;font-size:1.2rem}@media screen and (max-width:42em){.project-author,.project-date{font-size:1rem}}.main-content,.toc{max-width:64rem;padding:2rem 4rem;margin:0 auto;font-size:1.1rem}.toc{padding-bottom:0}.toc .toc-box{padding:1.5rem;background-color:#f3f6fa;border:solid 1px #dce6f0;border-radius:.3rem}.toc .toc-box .toc-title{margin:0 0 .5rem;text-align:center}.toc .toc-box>ul{margin:0;padding-left:1.5rem}@media screen and (min-width:42em) and (max-width:64em){.toc{padding:2rem 2rem 0}}@media screen and (max-width:42em){.toc{padding:2rem 1rem 0;font-size:1rem}}.main-content :first-child{margin-top:0}@media screen and (min-width:42em) and (max-width:64em){.main-content{padding:2rem}}@media screen and (max-width:42em){.main-content{padding:2rem 1rem;font-size:1rem}}.main-content img{max-width:100%}.main-content h1,.main-content h2,.main-content h3,.main-content h4,.main-content h5,.main-content h6{margin-top:2rem;margin-bottom:1rem;font-weight:400;color:#159957}.main-content p{margin-bottom:1em}.main-content code{padding:2px 4px;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;color:#567482;background-color:#f3f6fa;border-radius:.3rem}.main-content pre{padding:.8rem;margin-top:0;margin-bottom:1rem;font:1rem Consolas,"Liberation Mono",Menlo,Courier,monospace;color:#567482;word-wrap:normal;background-color:#f3f6fa;border:solid 1px #dce6f0;border-radius:.3rem;line-height:1.45;overflow:auto}@media screen and (max-width:42em){.main-content pre{font-size:.9rem}}.main-content pre>code{padding:0;margin:0;color:#567482;word-break:normal;white-space:pre;background:0 0;border:0}@media screen and (max-width:42em){.main-content pre>code{font-size:.9rem}}.main-content pre code,.main-content pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}.main-content pre code:after,.main-content pre code:before,.main-content pre tt:after,.main-content pre tt:before{content:normal}.main-content ol,.main-content ul{margin-top:0}.main-content blockquote{padding:0 1rem;margin-left:0;color:#819198;border-left:.3rem solid #dce6f0;font-size:1.2rem}.main-content blockquote>:first-child{margin-top:0}.main-content blockquote>:last-child{margin-bottom:0}@media screen and (max-width:42em){.main-content blockquote{font-size:1.1rem}}.main-content table{width:100%;overflow:auto;word-break:normal;word-break:keep-all;-webkit-overflow-scrolling:touch;border-collapse:collapse;border-spacing:0;margin:1rem 0}.main-content table th{font-weight:700;background-color:#159957;color:#fff}.main-content table td,.main-content table th{padding:.5rem 1rem;border-bottom:1px solid #e9ebec;text-align:left}.main-content table tr:nth-child(odd){background-color:#f2f2f2}.main-content dl{padding:0}.main-content dl dt{padding:0;margin-top:1rem;font-size:1rem;font-weight:700}.main-content dl dd{padding:0;margin-bottom:1rem}.main-content hr{height:2px;padding:0;margin:1rem 0;background-color:#eff0f1;border:0}code span.kw { color: #a71d5d; font-weight: normal; } 
code span.dt { color: #795da3; } 
code span.dv { color: #0086b3; } 
code span.bn { color: #0086b3; } 
code span.fl { color: #0086b3; } 
code span.ch { color: #4070a0; } 
code span.st { color: #183691; } 
code span.co { color: #969896; font-style: italic; } 
code span.ot { color: #007020; } 
</style>





</head>

<body>




<section class="page-header">
<h1 class="title toc-ignore project-name">Data Science In-Class Kaggle Competition Report</h1>
<h4 class="author project-author">Bruno Helmeczy</h4>
<h4 class="date project-date">11/04/2021</h4>
</section>


<div id="TOC" class="toc">
<div class="toc-box">
<ul>
<li><a href="#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#eda-transformations"><span class="toc-section-number">2</span> EDA Transformations</a></li>
<li><a href="#setup---helper-functions-parallel-processing"><span class="toc-section-number">3</span> Setup - Helper Functions &amp; Parallel Processing</a></li>
<li><a href="#modelling"><span class="toc-section-number">4</span> Modelling</a><ul>
<li><a href="#penalized-linear-models"><span class="toc-section-number">4.1</span> Penalized Linear Models</a></li>
<li><a href="#random-forests"><span class="toc-section-number">4.2</span> Random Forests</a></li>
<li><a href="#gradient-boosting-machines"><span class="toc-section-number">4.3</span> Gradient Boosting Machines</a></li>
<li><a href="#extreme-gradient-boosting-machines"><span class="toc-section-number">4.4</span> eXtreme Gradient Boosting Machines</a></li>
<li><a href="#neural-nets"><span class="toc-section-number">4.5</span> Neural Nets</a></li>
</ul></li>
<li><a href="#lessons-learned"><span class="toc-section-number">5</span> Lessons Learned</a></li>
<li><a href="#conclusion"><span class="toc-section-number">6</span> Conclusion</a></li>
</ul>
</div>
</div>

<section class="main-content">
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>This report summarizes my efforts undertaken as part of the in-house Kaggle Competition for the Data Science 2: Machine Learning Tools class at the Central European University, as part of the MSc in Business Analytics program. As part of the competition, at the risk of overkill, I submitted 69 predictions to the platform, achieving a best AUC score of 72.11%, which as of writing this report leads the public leaderboard. Below I try to present my approach in a semi-blog post format, avoiding so much detail as to disinterest readers, but clarifying methods tried, key lessons learned, &amp; helper functions / processes put in place to enable submitting so many predictions efficiently. I do this by 1st presenting resulting tranformations from my EDA, &amp; helper functions, then taking a high-level overview of my modelling efforts, &amp; finally concluding a few lessons / key-takeaways learned that could be of help for future Kaggle competitions.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(readr)</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="kw">library</span>(data.table)</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="kw">library</span>(caret)</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="kw">library</span>(gbm)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="kw">library</span>(rpart.plot)</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="kw">library</span>(MLeval)</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="kw">library</span>(pROC)</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="kw">library</span>(caTools)</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="kw">library</span>(viridis)</span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="kw">library</span>(ggthemes)</span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="kw">library</span>(dplyr)</span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="kw">library</span>(stringr)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">setwd</span>(<span class="st">&quot;C:/Users/helme/Desktop/CEU/WINTER_Term/Data_Science/Machine_Learning_Courses_DS1-3/DS2/Kaggle&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2"></a>df_train &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;train.csv&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb2-3"><a href="#cb2-3"></a>df_test &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;test.csv&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span></code></pre></div>
</div>
<div id="eda-transformations" class="section level1">
<h1><span class="header-section-number">2</span> EDA Transformations</h1>
<p>My sole source of transformations relied on variable histograms. I aimed to achieve quasi-normally distributed values for any given variable, without regard how the target variables probability changes conditioned on a predictor variable of interest. Since i have 58 predictor variables, I figured collapsing the feature space to 2 dimensions doesnt adequetely capture any possible association pattern, and so introducing splines, polynomials &amp; what not based on these 2d representations would seem to do more harm then good. As such, after observing the <code>Histograms</code> object outputs, I 1st filtered outlier values from <code>n_unique_tokens</code>, <code>num_hrefs</code> &amp; <code>n_tokens_content</code>, then applied appropriate transformations. These were either <code>log()</code> or <code>exp()</code> transformations, or in some cases reducing a variable to binary, using <code>ifelse()</code>, while using flag-variables where the raw value was zero . Finally, I wrapped all variable transformations into a function, to be able to transform the test data conveniently when I want to.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>Histograms &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="kw">colnames</span>(df_train), <span class="cf">function</span>(x) {</span>
<span id="cb3-2"><a href="#cb3-2"></a>  <span class="cf">if</span> (df_train[,x] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">is.numeric</span>() ) {</span>
<span id="cb3-3"><a href="#cb3-3"></a>    df_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes_string</span>(<span class="dt">x=</span>x)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="st">      </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;Distribution of &quot;</span>, x,<span class="st">&quot; Variable&quot;</span>))    </span>
<span id="cb3-5"><a href="#cb3-5"></a>  } <span class="cf">else</span> {</span>
<span id="cb3-6"><a href="#cb3-6"></a>    <span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;Variable &quot;</span>,x, <span class="st">&quot; is not numeric&quot;</span>))</span>
<span id="cb3-7"><a href="#cb3-7"></a>  }</span>
<span id="cb3-8"><a href="#cb3-8"></a>})</span>
<span id="cb3-9"><a href="#cb3-9"></a></span>
<span id="cb3-10"><a href="#cb3-10"></a>df_train &lt;-<span class="st"> </span>df_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(</span>
<span id="cb3-11"><a href="#cb3-11"></a>  n_unique_tokens <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb3-12"><a href="#cb3-12"></a>  num_hrefs <span class="op">&lt;=</span><span class="st"> </span><span class="dv">100</span>,</span>
<span id="cb3-13"><a href="#cb3-13"></a>  n_tokens_content <span class="op">&lt;=</span><span class="st"> </span><span class="dv">4000</span>) </span>
<span id="cb3-14"><a href="#cb3-14"></a></span>
<span id="cb3-15"><a href="#cb3-15"></a>Df_Transforms &lt;-<span class="st"> </span><span class="cf">function</span>(df_<span class="dv">2</span>_transform) {</span>
<span id="cb3-16"><a href="#cb3-16"></a>  df_<span class="dv">2</span>_transform &lt;-<span class="st"> </span>df_<span class="dv">2</span>_transform <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="st">    </span><span class="kw">mutate</span>(</span>
<span id="cb3-18"><a href="#cb3-18"></a>      <span class="dt">abs_title_sentiment_polarity =</span> base<span class="op">::</span><span class="kw">ifelse</span>(abs_title_sentiment_polarity <span class="op">==</span><span class="st"> </span><span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb3-19"><a href="#cb3-19"></a>      <span class="dt">title_sentiment_polarity =</span> base<span class="op">::</span><span class="kw">ifelse</span>(title_sentiment_polarity <span class="op">==</span><span class="st"> </span><span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb3-20"><a href="#cb3-20"></a>      <span class="dt">max_negative_polarity =</span> max_negative_polarity <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">exp</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">exp</span>(),</span>
<span id="cb3-21"><a href="#cb3-21"></a>      <span class="dt">max_positive_polarity =</span> base<span class="op">::</span><span class="kw">ifelse</span>(max_positive_polarity <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.9</span>,<span class="dv">1</span>,<span class="dv">0</span>),</span>
<span id="cb3-22"><a href="#cb3-22"></a>      <span class="dt">min_positive_polarity =</span> (min_positive_polarity<span class="fl">+0.01</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log</span>(),</span>
<span id="cb3-23"><a href="#cb3-23"></a>      <span class="dt">LDA_04 =</span> base<span class="op">::</span><span class="kw">ifelse</span>(LDA_<span class="dv">04</span> <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span>,<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb3-24"><a href="#cb3-24"></a>      <span class="dt">LDA_03 =</span> base<span class="op">::</span><span class="kw">ifelse</span>(LDA_<span class="dv">03</span> <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span>,<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb3-25"><a href="#cb3-25"></a>      <span class="dt">LDA_02 =</span> base<span class="op">::</span><span class="kw">ifelse</span>(LDA_<span class="dv">02</span> <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span>,<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb3-26"><a href="#cb3-26"></a>      <span class="dt">LDA_01 =</span> base<span class="op">::</span><span class="kw">ifelse</span>(LDA_<span class="dv">01</span> <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span>,<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb3-27"><a href="#cb3-27"></a>      <span class="dt">self_reference_avg_sharess =</span> (self_reference_avg_sharess<span class="op">+</span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log</span>(),</span>
<span id="cb3-28"><a href="#cb3-28"></a>      <span class="dt">self_reference_min_shares =</span> (self_reference_min_shares<span class="op">+</span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log</span>(),</span>
<span id="cb3-29"><a href="#cb3-29"></a>      <span class="dt">kw_max_avg =</span> (kw_max_avg <span class="op">+</span><span class="st"> </span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log</span>(),</span>
<span id="cb3-30"><a href="#cb3-30"></a>      <span class="dt">kw_min_avg_flag =</span> base<span class="op">::</span><span class="kw">ifelse</span>(kw_min_avg <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb3-31"><a href="#cb3-31"></a>      <span class="dt">kw_max_max_flag =</span> base<span class="op">::</span><span class="kw">ifelse</span>(kw_max_max <span class="op">&lt;</span><span class="st"> </span><span class="kw">max</span>(kw_max_max),<span class="dv">1</span>,<span class="dv">0</span>),</span>
<span id="cb3-32"><a href="#cb3-32"></a>      <span class="dt">kw_min_max_flag =</span> base<span class="op">::</span><span class="kw">ifelse</span>(kw_min_max <span class="op">==</span><span class="st"> </span><span class="dv">0</span> ,<span class="dv">1</span>,<span class="dv">0</span>),</span>
<span id="cb3-33"><a href="#cb3-33"></a>      <span class="dt">kw_min_max =</span> (kw_min_max <span class="op">+</span><span class="st"> </span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log</span>(),</span>
<span id="cb3-34"><a href="#cb3-34"></a>      <span class="dt">num_videos_flag =</span> base<span class="op">::</span><span class="kw">ifelse</span>(num_videos <span class="op">==</span><span class="st"> </span><span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>),</span>
<span id="cb3-35"><a href="#cb3-35"></a>      <span class="dt">num_imgs =</span> (num_imgs <span class="op">+</span><span class="st"> </span><span class="dv">1</span> ) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log</span>(),</span>
<span id="cb3-36"><a href="#cb3-36"></a>      <span class="dt">num_hrefs_log =</span> (num_hrefs <span class="op">+</span><span class="st"> </span><span class="dv">1</span> ) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log</span>(),</span>
<span id="cb3-37"><a href="#cb3-37"></a>      <span class="dt">n_non_stop_words =</span> base<span class="op">::</span><span class="kw">ifelse</span>(<span class="kw">round</span>(n_non_stop_words,<span class="dv">3</span>) <span class="op">==</span><span class="st"> </span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>),</span>
<span id="cb3-38"><a href="#cb3-38"></a>      <span class="dt">n_tokens_content =</span> (n_tokens_content<span class="op">+</span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log</span>()</span>
<span id="cb3-39"><a href="#cb3-39"></a>    )  </span>
<span id="cb3-40"><a href="#cb3-40"></a>  <span class="kw">return</span>(df_<span class="dv">2</span>_transform)</span>
<span id="cb3-41"><a href="#cb3-41"></a>}</span>
<span id="cb3-42"><a href="#cb3-42"></a>df_train &lt;-<span class="st"> </span><span class="kw">Df_Transforms</span>(df_train) </span>
<span id="cb3-43"><a href="#cb3-43"></a>df_train<span class="op">$</span>is_popular &lt;-<span class="st"> </span><span class="kw">factor</span>(df_train<span class="op">$</span>is_popular, <span class="dt">level =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Yes&quot;</span>,<span class="st">&quot;No&quot;</span>))</span></code></pre></div>
</div>
<div id="setup---helper-functions-parallel-processing" class="section level1">
<h1><span class="header-section-number">3</span> Setup - Helper Functions &amp; Parallel Processing</h1>
<p>Throughout my Modeling efforts, I wanted a quick &amp; convenient way to check model performance, be that cross-validated AUC values, or AUC values on a validation dataset. <code>GetCV_AUCs()</code> does the former, while <code>Get_ExSample_AUCs()</code> the latter. The same goes for easily creating predictions from a (set of) model(s), which is achieved by <code>Get_ExSample_Preds()</code>.</p>
<p><code>GetCV_AUCs()</code> loops through every fold of every model, after finding model results for the selected besttune, calculates &amp; stores AUC values for every fold, then calculates its mean AUC value for every model. In essence this replicates the <code>resamples()</code> function from <code>caret</code>, but can be applied also when using different cross-validation types, though that may be akin to comparing apples to oranges. An alternative, probably simpler approach would find the highest ROC value in every model objects <code>results</code> table, since we are to select based on the ROC metric.</p>
<p><code>Get_ExSample_AUCs()</code> takes a validation dataset, &amp; loops through a named list of models, to generate a probability prediction with <code>caret::predict(,type = &quot;prob&quot;)</code>. This yields 2 columns, the complementary probabilities of eithre value of the target variable. I arbitrariliy take the 1st column, of Yes, then I calculate AUC values with <code>pROC::roc()</code> &amp; get rid of the predictions themselves.</p>
<p><code>Get_ExSample_Preds()</code> similarly to <code>Get_ExSample_AUCs()</code> makes predictions, &amp; optionally generates csv files with the respective models name, while also returning a dataframe of predictions, useful for finding linear combinations of prediction, i.e.model stacking, or calling <code>stats::cor()</code> to check predictions correlations.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># 0) Helper Functions ----</span></span>
<span id="cb4-2"><a href="#cb4-2"></a></span>
<span id="cb4-3"><a href="#cb4-3"></a>GetCV_AUCs &lt;-<span class="st"> </span><span class="cf">function</span>(named_model_list,control_value) {</span>
<span id="cb4-4"><a href="#cb4-4"></a>  CV_AUC_folds &lt;-<span class="st"> </span><span class="kw">list</span>()</span>
<span id="cb4-5"><a href="#cb4-5"></a>  </span>
<span id="cb4-6"><a href="#cb4-6"></a>  <span class="cf">for</span> (model_name <span class="cf">in</span> <span class="kw">names</span>(named_model_list)) {</span>
<span id="cb4-7"><a href="#cb4-7"></a>    auc &lt;-<span class="st"> </span><span class="kw">list</span>()</span>
<span id="cb4-8"><a href="#cb4-8"></a>    model &lt;-<span class="st"> </span>named_model_list[[model_name]]</span>
<span id="cb4-9"><a href="#cb4-9"></a>    </span>
<span id="cb4-10"><a href="#cb4-10"></a>    <span class="cf">for</span> (fold <span class="cf">in</span> model<span class="op">$</span>pred<span class="op">$</span>Resample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unique</span>()) {</span>
<span id="cb4-11"><a href="#cb4-11"></a>      cv_fold &lt;-<span class="st"> </span>model<span class="op">$</span>pred <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Resample <span class="op">==</span><span class="st"> </span>fold)</span>
<span id="cb4-12"><a href="#cb4-12"></a>      TuneParams &lt;-<span class="st"> </span>model<span class="op">$</span>bestTune <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">colnames</span>()</span>
<span id="cb4-13"><a href="#cb4-13"></a>      </span>
<span id="cb4-14"><a href="#cb4-14"></a>      <span class="cf">for</span> (param <span class="cf">in</span> TuneParams) {</span>
<span id="cb4-15"><a href="#cb4-15"></a>        cv_fold &lt;-<span class="st"> </span>cv_fold[cv_fold[,param] <span class="op">==</span><span class="st"> </span>model<span class="op">$</span>bestTune[,param],]</span>
<span id="cb4-16"><a href="#cb4-16"></a>      }</span>
<span id="cb4-17"><a href="#cb4-17"></a>      </span>
<span id="cb4-18"><a href="#cb4-18"></a>      roc_obj &lt;-<span class="st"> </span><span class="kw">roc</span>(cv_fold<span class="op">$</span>obs, cv_fold[,<span class="kw">c</span>(control_value)])</span>
<span id="cb4-19"><a href="#cb4-19"></a>      auc[[fold]] &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(roc_obj<span class="op">$</span>auc) </span>
<span id="cb4-20"><a href="#cb4-20"></a>    }</span>
<span id="cb4-21"><a href="#cb4-21"></a>    </span>
<span id="cb4-22"><a href="#cb4-22"></a>    CV_AUC_folds[[model_name]] &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;Resample&quot;</span> =<span class="st"> </span><span class="kw">names</span>(auc),</span>
<span id="cb4-23"><a href="#cb4-23"></a>                                             <span class="st">&quot;AUC&quot;</span> =<span class="st"> </span><span class="kw">unlist</span>(auc))</span>
<span id="cb4-24"><a href="#cb4-24"></a>  }</span>
<span id="cb4-25"><a href="#cb4-25"></a>  </span>
<span id="cb4-26"><a href="#cb4-26"></a>  CV_AUC &lt;-<span class="st"> </span><span class="kw">list</span>()</span>
<span id="cb4-27"><a href="#cb4-27"></a>  <span class="cf">for</span> (model_name <span class="cf">in</span> <span class="kw">names</span>(named_model_list)) {</span>
<span id="cb4-28"><a href="#cb4-28"></a>    CV_AUC[[model_name]] &lt;-<span class="st"> </span><span class="kw">mean</span>(CV_AUC_folds[[model_name]]<span class="op">$</span>AUC) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">4</span>)</span>
<span id="cb4-29"><a href="#cb4-29"></a>  }</span>
<span id="cb4-30"><a href="#cb4-30"></a>  </span>
<span id="cb4-31"><a href="#cb4-31"></a>  AUCs &lt;-<span class="st"> </span>CV_AUC <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">cbind</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb4-32"><a href="#cb4-32"></a>  <span class="kw">colnames</span>(AUCs) &lt;-<span class="st"> &quot;Model_AUC&quot;</span></span>
<span id="cb4-33"><a href="#cb4-33"></a>  </span>
<span id="cb4-34"><a href="#cb4-34"></a>  <span class="kw">return</span>(AUCs)</span>
<span id="cb4-35"><a href="#cb4-35"></a>}</span>
<span id="cb4-36"><a href="#cb4-36"></a></span>
<span id="cb4-37"><a href="#cb4-37"></a>Get_ExSample_AUCs &lt;-<span class="st"> </span><span class="cf">function</span>(named_model_list, test_df) {</span>
<span id="cb4-38"><a href="#cb4-38"></a>  ExSample_AUCs &lt;-<span class="st"> </span><span class="kw">list</span>()</span>
<span id="cb4-39"><a href="#cb4-39"></a>  </span>
<span id="cb4-40"><a href="#cb4-40"></a>  <span class="cf">for</span> (model <span class="cf">in</span> <span class="kw">names</span>(named_model_list)) {</span>
<span id="cb4-41"><a href="#cb4-41"></a>    Pred &lt;-<span class="st"> </span><span class="kw">predict</span>(named_model_list[[model]],<span class="dt">newdata =</span> test_df, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb4-42"><a href="#cb4-42"></a>    test_df[,model] &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(Pred)[,<span class="dv">1</span>]</span>
<span id="cb4-43"><a href="#cb4-43"></a>    test_df<span class="op">$</span>pred &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(Pred)[,<span class="dv">1</span>]</span>
<span id="cb4-44"><a href="#cb4-44"></a>    ExSample_AUCs[[model]] &lt;-<span class="st"> </span><span class="kw">roc</span>(test_df<span class="op">$</span>is_popular,test_df<span class="op">$</span>pred)<span class="op">$</span>auc <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">4</span>)</span>
<span id="cb4-45"><a href="#cb4-45"></a>  }</span>
<span id="cb4-46"><a href="#cb4-46"></a>  </span>
<span id="cb4-47"><a href="#cb4-47"></a>  findf &lt;-<span class="st"> </span>ExSample_AUCs <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">cbind</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb4-48"><a href="#cb4-48"></a>  <span class="kw">colnames</span>(findf) &lt;-<span class="st"> &quot;Ex_Sample_AUC&quot;</span></span>
<span id="cb4-49"><a href="#cb4-49"></a>  test_df<span class="op">$</span>pred &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb4-50"><a href="#cb4-50"></a>  <span class="kw">return</span>(findf)</span>
<span id="cb4-51"><a href="#cb4-51"></a>}</span>
<span id="cb4-52"><a href="#cb4-52"></a></span>
<span id="cb4-53"><a href="#cb4-53"></a>Get_ExSample_Preds &lt;-<span class="st"> </span><span class="cf">function</span>(named_model_list, test_df,  <span class="dt">Gen_CSVs =</span> <span class="ot">FALSE</span>) {</span>
<span id="cb4-54"><a href="#cb4-54"></a>  ExSample_Preds &lt;-<span class="st"> </span><span class="kw">list</span>()</span>
<span id="cb4-55"><a href="#cb4-55"></a>  </span>
<span id="cb4-56"><a href="#cb4-56"></a>  model &lt;-<span class="st"> </span><span class="kw">names</span>(named_model_list)[<span class="dv">1</span>]</span>
<span id="cb4-57"><a href="#cb4-57"></a>  <span class="cf">for</span> (model <span class="cf">in</span> <span class="kw">names</span>(named_model_list)) {</span>
<span id="cb4-58"><a href="#cb4-58"></a>    Pred &lt;-<span class="st"> </span><span class="kw">predict</span>(named_model_list[[model]],<span class="dt">newdata =</span> test_df, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb4-59"><a href="#cb4-59"></a>    ExSample_Preds[[model]] &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(Pred)[,<span class="dv">1</span>]</span>
<span id="cb4-60"><a href="#cb4-60"></a>    </span>
<span id="cb4-61"><a href="#cb4-61"></a>    <span class="cf">if</span> (Gen_CSVs <span class="op">==</span><span class="st"> </span><span class="ot">TRUE</span>) {</span>
<span id="cb4-62"><a href="#cb4-62"></a>      SubFile &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb4-63"><a href="#cb4-63"></a>      SubFile<span class="op">$</span>article_id &lt;-<span class="st"> </span>test_df<span class="op">$</span>article_id</span>
<span id="cb4-64"><a href="#cb4-64"></a>      SubFile<span class="op">$</span>score &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(Pred)[,<span class="dv">1</span>]</span>
<span id="cb4-65"><a href="#cb4-65"></a>      SubFile &lt;-<span class="st"> </span>SubFile <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb4-66"><a href="#cb4-66"></a>      </span>
<span id="cb4-67"><a href="#cb4-67"></a>      readr<span class="op">::</span><span class="kw">write_csv</span>(SubFile,<span class="kw">paste0</span>(<span class="st">&quot;BH_DS2_&quot;</span>,<span class="kw">Sys.Date</span>(),<span class="st">&quot;_&quot;</span>,model,<span class="st">&quot;_model_sub.csv&quot;</span>))</span>
<span id="cb4-68"><a href="#cb4-68"></a>    }</span>
<span id="cb4-69"><a href="#cb4-69"></a>  }</span>
<span id="cb4-70"><a href="#cb4-70"></a>  ExSample_Preds &lt;-<span class="st"> </span>ExSample_Preds <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb4-71"><a href="#cb4-71"></a>  <span class="kw">return</span>(ExSample_Preds)</span>
<span id="cb4-72"><a href="#cb4-72"></a>}</span></code></pre></div>
<p>My next setup trick was to allow parallel processing of models. As intend to use repeated cross-validation for more robust results, foreseeably long tuning grids, &amp; I also like to think my PC is fairly strong, I tried commiting more processing power to my modelling efforts. I did so with the <code>parallel</code> &amp; <code>doParallel</code> packages, by 1st detecting the number of cores in my PC with <code>detectCores()</code>, then creating a cluster with <code>makePSOCKcluster()</code> with given number of cores (in this case 6 of 8, to allow my PC to be useful while models are running), &amp; finally using <code>registerDoParallel()</code> to launch the cluster. From this point on, <code>caret::trainControl()</code> function sets the argument <code>allowParallel</code> to TRUE by default, making any model run in parallel as possible (e.g.tree-based models are better suited for parallel processing vs penalized models, though in any case different folds of a model are suitable), When finished, the <code>stopCluster()</code> function de-registers the cluster.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co">#install.packages(&#39;parallel&#39;)</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co">#install.packages(&quot;doParallel&quot;)</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="kw">library</span>(doParallel)</span>
<span id="cb5-4"><a href="#cb5-4"></a><span class="kw">library</span>(parallel)</span>
<span id="cb5-5"><a href="#cb5-5"></a></span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="co"># Check Nr of cores &amp; make cluster of it</span></span>
<span id="cb5-7"><a href="#cb5-7"></a>no_cores &lt;-<span class="st"> </span><span class="kw">detectCores</span>(<span class="dt">logical =</span> <span class="ot">TRUE</span>)</span>
<span id="cb5-8"><a href="#cb5-8"></a>cl &lt;-<span class="st"> </span><span class="kw">makePSOCKcluster</span>(no_cores<span class="dv">-2</span>)</span>
<span id="cb5-9"><a href="#cb5-9"></a></span>
<span id="cb5-10"><a href="#cb5-10"></a><span class="kw">registerDoParallel</span>(cl) <span class="co"># Register Cluster for parallel processing</span></span>
<span id="cb5-11"><a href="#cb5-11"></a><span class="kw">stopCluster</span>(cl) <span class="co">## When you are done: Do before shutting down :D </span></span></code></pre></div>
</div>
<div id="modelling" class="section level1">
<h1><span class="header-section-number">4</span> Modelling</h1>
<p>Throughout my modelling journey for this competition, I certainly tried various train-validation splits of the data, as much as different trainControl methods. after a very brief stint of using train-validate-test split, I merged the train &amp; validation datasets to obtain 2 train-validation splits, 75-25 &amp; 80-20 splits.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="co">###  80-20 split -&gt; for 10x3 CVwith indices ----</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb6-3"><a href="#cb6-3"></a>train_indices &lt;-<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">createDataPartition</span>(df_train<span class="op">$</span>is_popular, <span class="dt">p =</span> <span class="fl">0.5</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>))</span>
<span id="cb6-4"><a href="#cb6-4"></a>data_train &lt;-<span class="st"> </span>df_train[train_indices, ]</span>
<span id="cb6-5"><a href="#cb6-5"></a>data_holdout &lt;-<span class="st"> </span>df_train[<span class="op">-</span>train_indices, ]</span>
<span id="cb6-6"><a href="#cb6-6"></a></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb6-8"><a href="#cb6-8"></a>train_indices &lt;-<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">createDataPartition</span>(data_holdout<span class="op">$</span>is_popular, <span class="dt">p =</span> <span class="fl">0.6</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>))</span>
<span id="cb6-9"><a href="#cb6-9"></a>data_validate &lt;-<span class="st"> </span>data_holdout[train_indices, ]</span>
<span id="cb6-10"><a href="#cb6-10"></a>data_test &lt;-<span class="st"> </span>data_holdout[<span class="op">-</span>train_indices, ]</span>
<span id="cb6-11"><a href="#cb6-11"></a>data_holdout &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb6-12"><a href="#cb6-12"></a>data_valid_n_train &lt;-<span class="st"> </span><span class="kw">rbind</span>(data_train, data_validate)</span>
<span id="cb6-13"><a href="#cb6-13"></a></span>
<span id="cb6-14"><a href="#cb6-14"></a><span class="co">### 75-25</span></span>
<span id="cb6-15"><a href="#cb6-15"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb6-16"><a href="#cb6-16"></a>train_indices_<span class="dv">75</span> &lt;-<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">createDataPartition</span>(df_train<span class="op">$</span>is_popular, <span class="dt">p =</span> <span class="fl">0.75</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>))</span>
<span id="cb6-17"><a href="#cb6-17"></a>data_valid_n_train_<span class="dv">75</span> &lt;-<span class="st"> </span>df_train[train_indices_<span class="dv">75</span>, ]</span>
<span id="cb6-18"><a href="#cb6-18"></a>data_holdout_<span class="dv">25</span> &lt;-<span class="st"> </span>df_train[<span class="op">-</span>train_indices_<span class="dv">75</span>, ]</span></code></pre></div>
<p>Appropriately, I would also have different traincontrol objects for the 2 train-test splits, while also trying out 5x5 &amp; 10x3 repeated cross-validations. Note that in all cases I speciifed explicitly the rox indices to be used in each fold, using the <code>createFolds()</code> &amp; <code>createMultiFolds()</code> functions. I made the mistake however that i specified an object resulting from <code>createFolds</code> as indexes into the 1st traincontrol object, eventhough i wanted to do repeated cross-validation. Thus, unknowingly, my early modelling attempt all used simple cross-validation, hence the multiple traincontrol objects. Also note, that in the interest of saving memory, I did not save any Predictions, &amp; specificed allowParallel explicitly, eventhough it is set to true by defualt.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># 10-fold cross validation - Rep 3x ----</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>MyFolds &lt;-<span class="st"> </span><span class="kw">createFolds</span>(data_valid_n_train<span class="op">$</span>is_popular, <span class="dt">k =</span> <span class="dv">10</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a>MyFolds_10x3 &lt;-<span class="st"> </span><span class="kw">createMultiFolds</span>(data_valid_n_train<span class="op">$</span>is_popular, <span class="dt">k =</span> <span class="dv">10</span>, <span class="dt">times =</span> <span class="dv">3</span>)</span>
<span id="cb7-4"><a href="#cb7-4"></a>MyFolds_10x3_<span class="dv">75</span> &lt;-<span class="st"> </span><span class="kw">createMultiFolds</span>(data_valid_n_train_<span class="dv">75</span><span class="op">$</span>is_popular, <span class="dt">k =</span> <span class="dv">10</span>, <span class="dt">times =</span> <span class="dv">3</span>)</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a>train_control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(</span>
<span id="cb7-7"><a href="#cb7-7"></a>  <span class="dt">index =</span> MyFolds,</span>
<span id="cb7-8"><a href="#cb7-8"></a>  <span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb7-9"><a href="#cb7-9"></a>  <span class="dt">number =</span> <span class="dv">10</span>,</span>
<span id="cb7-10"><a href="#cb7-10"></a>  <span class="dt">repeats =</span> <span class="dv">3</span>,</span>
<span id="cb7-11"><a href="#cb7-11"></a><span class="co">#  verboseIter = TRUE,</span></span>
<span id="cb7-12"><a href="#cb7-12"></a>  <span class="dt">summaryFunction =</span> twoClassSummary,</span>
<span id="cb7-13"><a href="#cb7-13"></a>  <span class="dt">classProbs =</span> T,</span>
<span id="cb7-14"><a href="#cb7-14"></a>  <span class="dt">savePredictions =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb7-15"><a href="#cb7-15"></a>  <span class="dt">allowParallel =</span> <span class="ot">TRUE</span>)</span>
<span id="cb7-16"><a href="#cb7-16"></a></span>
<span id="cb7-17"><a href="#cb7-17"></a><span class="co"># 10x3_80 ----</span></span>
<span id="cb7-18"><a href="#cb7-18"></a>train_control_<span class="dv">10</span>_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">trainControl</span>(</span>
<span id="cb7-19"><a href="#cb7-19"></a>  <span class="dt">index =</span> MyFolds_10x3,</span>
<span id="cb7-20"><a href="#cb7-20"></a>  <span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb7-21"><a href="#cb7-21"></a>  <span class="dt">number =</span> <span class="dv">10</span>,</span>
<span id="cb7-22"><a href="#cb7-22"></a>  <span class="dt">repeats =</span> <span class="dv">3</span>,</span>
<span id="cb7-23"><a href="#cb7-23"></a>  <span class="dt">verboseIter =</span> <span class="ot">TRUE</span>,</span>
<span id="cb7-24"><a href="#cb7-24"></a>  <span class="dt">summaryFunction =</span> twoClassSummary,</span>
<span id="cb7-25"><a href="#cb7-25"></a>  <span class="dt">classProbs =</span> T,</span>
<span id="cb7-26"><a href="#cb7-26"></a>  <span class="dt">savePredictions =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb7-27"><a href="#cb7-27"></a>  <span class="dt">allowParallel =</span> <span class="ot">TRUE</span>)</span>
<span id="cb7-28"><a href="#cb7-28"></a></span>
<span id="cb7-29"><a href="#cb7-29"></a><span class="co"># 10x3_75 ----</span></span>
<span id="cb7-30"><a href="#cb7-30"></a>train_control_<span class="dv">10</span>_<span class="dv">3</span>_<span class="dv">75</span> &lt;-<span class="st"> </span><span class="kw">trainControl</span>(</span>
<span id="cb7-31"><a href="#cb7-31"></a>  <span class="dt">index =</span> MyFolds_10x3_<span class="dv">75</span>,</span>
<span id="cb7-32"><a href="#cb7-32"></a>  <span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb7-33"><a href="#cb7-33"></a>  <span class="dt">number =</span> <span class="dv">10</span>,</span>
<span id="cb7-34"><a href="#cb7-34"></a>  <span class="dt">repeats =</span> <span class="dv">3</span>,</span>
<span id="cb7-35"><a href="#cb7-35"></a>  <span class="dt">verboseIter =</span> <span class="ot">TRUE</span>,</span>
<span id="cb7-36"><a href="#cb7-36"></a>  <span class="dt">summaryFunction =</span> twoClassSummary,</span>
<span id="cb7-37"><a href="#cb7-37"></a>  <span class="dt">classProbs =</span> T,</span>
<span id="cb7-38"><a href="#cb7-38"></a>  <span class="dt">savePredictions =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb7-39"><a href="#cb7-39"></a>  <span class="dt">allowParallel =</span> <span class="ot">TRUE</span>)</span>
<span id="cb7-40"><a href="#cb7-40"></a></span>
<span id="cb7-41"><a href="#cb7-41"></a><span class="co"># Alternative: 5x5 repeated cv -----</span></span>
<span id="cb7-42"><a href="#cb7-42"></a>MyFolds_<span class="dv">5</span>_<span class="dv">5</span> &lt;-<span class="st"> </span><span class="kw">createMultiFolds</span>(data_valid_n_train_<span class="dv">75</span><span class="op">$</span>is_popular, <span class="dt">k =</span> <span class="dv">5</span>, <span class="dt">times =</span> <span class="dv">5</span>)</span>
<span id="cb7-43"><a href="#cb7-43"></a></span>
<span id="cb7-44"><a href="#cb7-44"></a>train_control_<span class="dv">5</span>_<span class="dv">5</span> &lt;-<span class="st"> </span><span class="kw">trainControl</span>(</span>
<span id="cb7-45"><a href="#cb7-45"></a>  <span class="dt">index =</span> MyFolds_<span class="dv">5</span>_<span class="dv">5</span>,</span>
<span id="cb7-46"><a href="#cb7-46"></a>  <span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb7-47"><a href="#cb7-47"></a>  <span class="dt">number =</span> <span class="dv">5</span>,</span>
<span id="cb7-48"><a href="#cb7-48"></a>  <span class="dt">repeats =</span> <span class="dv">5</span>,</span>
<span id="cb7-49"><a href="#cb7-49"></a>  <span class="dt">verboseIter =</span> <span class="ot">TRUE</span>,</span>
<span id="cb7-50"><a href="#cb7-50"></a>  <span class="dt">summaryFunction =</span> twoClassSummary,</span>
<span id="cb7-51"><a href="#cb7-51"></a>  <span class="dt">classProbs =</span> T,</span>
<span id="cb7-52"><a href="#cb7-52"></a>  <span class="dt">savePredictions =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb7-53"><a href="#cb7-53"></a>  <span class="dt">allowParallel =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<div id="penalized-linear-models" class="section level2">
<h2><span class="header-section-number">4.1</span> Penalized Linear Models</h2>
<p>My 1st models, serving as baselines, were penalized linear models, in 1 case simply regularizing predictor variables, in the other also utilizing PCA. I used all variables excluding article_id, while my prediction results were around 0.67-0.689 AUC. The best-tuned model yielded <code>alpha = 1</code> &amp; <code>lambda = 0.007</code>, i.e.returning a LASSO model.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># My E-Net Grid &amp; Model ----</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>ENet_tunegrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(</span>
<span id="cb8-3"><a href="#cb8-3"></a>  <span class="st">&quot;alpha&quot;</span>  =<span class="st"> </span>(<span class="dv">0</span><span class="op">:</span><span class="dv">10</span>)<span class="op">/</span><span class="dv">10</span>,</span>
<span id="cb8-4"><a href="#cb8-4"></a>  <span class="st">&quot;lambda&quot;</span> =<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">5</span>,<span class="dt">length=</span><span class="dv">150</span>)</span>
<span id="cb8-5"><a href="#cb8-5"></a>)</span>
<span id="cb8-6"><a href="#cb8-6"></a></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb8-8"><a href="#cb8-8"></a>Benchmark_GLM &lt;-<span class="st"> </span><span class="kw">train</span>(</span>
<span id="cb8-9"><a href="#cb8-9"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb8-10"><a href="#cb8-10"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb8-11"><a href="#cb8-11"></a>  <span class="dt">method =</span> <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb8-12"><a href="#cb8-12"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb8-13"><a href="#cb8-13"></a>  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,</span>
<span id="cb8-14"><a href="#cb8-14"></a>  <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>),</span>
<span id="cb8-15"><a href="#cb8-15"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb8-16"><a href="#cb8-16"></a>  <span class="dt">tuneGrid =</span> ENet_tunegrid,</span>
<span id="cb8-17"><a href="#cb8-17"></a>  <span class="dt">na.action =</span> na.exclude</span>
<span id="cb8-18"><a href="#cb8-18"></a>)</span>
<span id="cb8-19"><a href="#cb8-19"></a></span>
<span id="cb8-20"><a href="#cb8-20"></a><span class="co"># E_net w PCA ----</span></span>
<span id="cb8-21"><a href="#cb8-21"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb8-22"><a href="#cb8-22"></a>GLM_pca &lt;-<span class="st"> </span><span class="kw">train</span>(</span>
<span id="cb8-23"><a href="#cb8-23"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb8-24"><a href="#cb8-24"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb8-25"><a href="#cb8-25"></a>  <span class="dt">method =</span> <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb8-26"><a href="#cb8-26"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb8-27"><a href="#cb8-27"></a>  <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,</span>
<span id="cb8-28"><a href="#cb8-28"></a>  <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>,<span class="st">&quot;pca&quot;</span>),</span>
<span id="cb8-29"><a href="#cb8-29"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb8-30"><a href="#cb8-30"></a>  <span class="dt">tuneGrid =</span> ENet_tunegrid,</span>
<span id="cb8-31"><a href="#cb8-31"></a>  <span class="dt">na.action =</span> na.exclude</span>
<span id="cb8-32"><a href="#cb8-32"></a>)</span></code></pre></div>
</div>
<div id="random-forests" class="section level2">
<h2><span class="header-section-number">4.2</span> Random Forests</h2>
<p>My 2nd model family, Random Forests proved to be a meaningful improvement, already highlighted tree-based methods to be superior for the problem at hand. I tested <code>.mtry</code> for odd numbers between 1-21, &amp; minimum splitting node size between 5-45 by increments of 10. Interestingly, <code>.mtry = 1</code> proved to be the best choice, meaning the model preformed best when randomly selecting a variable based on which to split a node, suggesting there are hardly any variables which explain an articles popularity better than others. Random Forests did give a significant improvement over Penalized linear models however, reaching final AUC of 0.7124, i.e.it would have placed 1st on the public leaderboard during last years cohort (&amp; as of this writing 11th on the public leaderboard this year).</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># 2. b) Random Forest -----</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>rf_tune_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(</span>
<span id="cb9-3"><a href="#cb9-3"></a>  <span class="dt">.mtry =</span> (<span class="dv">1</span><span class="op">:</span><span class="dv">11</span>)<span class="op">*</span><span class="dv">2-1</span>,</span>
<span id="cb9-4"><a href="#cb9-4"></a>  <span class="dt">.splitrule =</span> <span class="st">&quot;gini&quot;</span>,</span>
<span id="cb9-5"><a href="#cb9-5"></a>  <span class="dt">.min.node.size =</span> <span class="kw">seq</span>(<span class="dv">5</span>,<span class="dv">45</span>,<span class="dt">by =</span> <span class="dv">10</span>) </span>
<span id="cb9-6"><a href="#cb9-6"></a>)</span>
<span id="cb9-7"><a href="#cb9-7"></a></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="co"># RF Re-Fit ----</span></span>
<span id="cb9-9"><a href="#cb9-9"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb9-10"><a href="#cb9-10"></a>RF_model_ReFit_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">train</span>(</span>
<span id="cb9-11"><a href="#cb9-11"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb9-12"><a href="#cb9-12"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb9-13"><a href="#cb9-13"></a>  <span class="dt">method =</span> <span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb9-14"><a href="#cb9-14"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb9-15"><a href="#cb9-15"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb9-16"><a href="#cb9-16"></a>  <span class="dt">tuneGrid =</span> rf_tune_grid,</span>
<span id="cb9-17"><a href="#cb9-17"></a>  <span class="dt">na.action=</span>na.exclude</span>
<span id="cb9-18"><a href="#cb9-18"></a>)</span>
<span id="cb9-19"><a href="#cb9-19"></a></span>
<span id="cb9-20"><a href="#cb9-20"></a><span class="co"># RF Re-Fit PCA ----</span></span>
<span id="cb9-21"><a href="#cb9-21"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb9-22"><a href="#cb9-22"></a>RF_ReFit_pca &lt;-<span class="st"> </span><span class="kw">train</span>(</span>
<span id="cb9-23"><a href="#cb9-23"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb9-24"><a href="#cb9-24"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb9-25"><a href="#cb9-25"></a>  <span class="dt">method =</span> <span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb9-26"><a href="#cb9-26"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb9-27"><a href="#cb9-27"></a>  <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>,<span class="st">&quot;pca&quot;</span>),</span>
<span id="cb9-28"><a href="#cb9-28"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb9-29"><a href="#cb9-29"></a>  <span class="dt">tuneGrid =</span> rf_tune_grid,</span>
<span id="cb9-30"><a href="#cb9-30"></a>  <span class="dt">na.action=</span>na.exclude</span>
<span id="cb9-31"><a href="#cb9-31"></a>)</span></code></pre></div>
</div>
<div id="gradient-boosting-machines" class="section level2">
<h2><span class="header-section-number">4.3</span> Gradient Boosting Machines</h2>
<p>I also applied GBM methods, though to no great avail. I tuned 2 models, testing interaction depths of 3,5,7,8; minimum required observations to split a node between 5-45 by intervals of 5; shrinkage of 0.001 - 0.01 &amp; between 500-1500 trees. My resulting AUC were around 0.69, so I gave up on this method to move onto XGBoost models.</p>
</div>
<div id="extreme-gradient-boosting-machines" class="section level2">
<h2><span class="header-section-number">4.4</span> eXtreme Gradient Boosting Machines</h2>
<p>Tuning this model family represents the bulk of my efforts in trying to win this competition, giving 49 of my 69 total prediction submissions. Part of the reason for this is an early indication of its potential, its 5th iteration already giving AUC of 0.715, another part of it being me not being too familiar with tuning XGBoost models, i.e.this context giving me a good opportunity to explore each tuning parameters effect on model performance. I like to think about this model tuning in terms of phases:</p>
<p><strong>Phase 1:</strong> As a 1st go to make XGB models work, I gave a range of value to each parameter, observed the tuning grids resulting models cross-validated AUC values &amp; defined the next models ranges based on those. 1 could also see a few obvious mistakes, e.g.<code>min_child_weight &lt; 1</code> in XGB1-3. After a little reading, I realised this is the equivalent of minimum required observations to split a node &amp; adjusted the tuning parameter appropriately afterwards. You can also see I started off testing large amount of trees, &amp; only by model 5 I tested 500 trees, which proved to be the best choice, along with maximum tree depth of 11, gamma &amp; eta of 0.01, min child weight of 1, subsample of 0.8 &amp; colsample-by-tree of 0.75. These parameters yielded an AUC of 0.71501, good for 8th place as of writing this report.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># 2. c2) XGBoost -----</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="co">## XGB1 ----</span></span>
<span id="cb10-3"><a href="#cb10-3"></a>xgb_grid &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb10-4"><a href="#cb10-4"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">2000</span>,<span class="dv">1250</span>),</span>
<span id="cb10-5"><a href="#cb10-5"></a>  <span class="dt">max_depth =</span> (<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>)<span class="op">*</span><span class="dv">2</span><span class="op">+</span><span class="dv">1</span>,</span>
<span id="cb10-6"><a href="#cb10-6"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.03</span>,<span class="fl">0.05</span>, <span class="fl">0.06</span>),</span>
<span id="cb10-7"><a href="#cb10-7"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb10-8"><a href="#cb10-8"></a>  <span class="dt">colsample_bytree =</span> <span class="kw">seq</span>(<span class="dv">75</span>,<span class="dv">95</span>,<span class="dt">by =</span><span class="dv">10</span> )<span class="op">/</span><span class="dv">100</span>,  </span>
<span id="cb10-9"><a href="#cb10-9"></a>  <span class="dt">min_child_weight =</span> (<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)<span class="op">/</span><span class="dv">10</span>,</span>
<span id="cb10-10"><a href="#cb10-10"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.75</span>))</span>
<span id="cb10-11"><a href="#cb10-11"></a></span>
<span id="cb10-12"><a href="#cb10-12"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb10-13"><a href="#cb10-13"></a>XGB_model &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb10-14"><a href="#cb10-14"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb10-15"><a href="#cb10-15"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb10-16"><a href="#cb10-16"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb10-17"><a href="#cb10-17"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb10-18"><a href="#cb10-18"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb10-19"><a href="#cb10-19"></a>  <span class="dt">tuneGrid=</span> xgb_grid)</span>
<span id="cb10-20"><a href="#cb10-20"></a></span>
<span id="cb10-21"><a href="#cb10-21"></a><span class="co">## XGB2 ----</span></span>
<span id="cb10-22"><a href="#cb10-22"></a>xgb_grid2 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb10-23"><a href="#cb10-23"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">1750</span>,<span class="dv">1250</span>),</span>
<span id="cb10-24"><a href="#cb10-24"></a>  <span class="dt">max_depth =</span> (<span class="dv">4</span><span class="op">:</span><span class="dv">5</span>)<span class="op">*</span><span class="dv">2</span><span class="op">+</span><span class="dv">1</span>,</span>
<span id="cb10-25"><a href="#cb10-25"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.02</span>,<span class="fl">0.03</span>),</span>
<span id="cb10-26"><a href="#cb10-26"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.01</span>,<span class="fl">0.02</span>),</span>
<span id="cb10-27"><a href="#cb10-27"></a>  <span class="dt">colsample_bytree =</span> <span class="fl">0.75</span>,  </span>
<span id="cb10-28"><a href="#cb10-28"></a>  <span class="dt">min_child_weight =</span> (<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)<span class="op">/</span><span class="dv">20</span>,</span>
<span id="cb10-29"><a href="#cb10-29"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>))</span>
<span id="cb10-30"><a href="#cb10-30"></a></span>
<span id="cb10-31"><a href="#cb10-31"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb10-32"><a href="#cb10-32"></a>XGB_model2 &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb10-33"><a href="#cb10-33"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb10-34"><a href="#cb10-34"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb10-35"><a href="#cb10-35"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb10-36"><a href="#cb10-36"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb10-37"><a href="#cb10-37"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb10-38"><a href="#cb10-38"></a>  <span class="dt">tuneGrid=</span> xgb_grid2)</span>
<span id="cb10-39"><a href="#cb10-39"></a></span>
<span id="cb10-40"><a href="#cb10-40"></a><span class="co">## XGB3 ----</span></span>
<span id="cb10-41"><a href="#cb10-41"></a>xgb_grid3 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb10-42"><a href="#cb10-42"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">1250</span>),</span>
<span id="cb10-43"><a href="#cb10-43"></a>  <span class="dt">max_depth =</span> (<span class="dv">5</span>)<span class="op">*</span><span class="dv">2</span><span class="op">+</span><span class="dv">1</span>,</span>
<span id="cb10-44"><a href="#cb10-44"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>,<span class="fl">0.02</span>),</span>
<span id="cb10-45"><a href="#cb10-45"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.01</span>,<span class="fl">0.02</span>),</span>
<span id="cb10-46"><a href="#cb10-46"></a>  <span class="dt">colsample_bytree =</span> <span class="fl">0.75</span>,  </span>
<span id="cb10-47"><a href="#cb10-47"></a>  <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">5</span>)<span class="op">/</span><span class="dv">20</span>,</span>
<span id="cb10-48"><a href="#cb10-48"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>))</span>
<span id="cb10-49"><a href="#cb10-49"></a></span>
<span id="cb10-50"><a href="#cb10-50"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb10-51"><a href="#cb10-51"></a>XGB_model3 &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb10-52"><a href="#cb10-52"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb10-53"><a href="#cb10-53"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb10-54"><a href="#cb10-54"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb10-55"><a href="#cb10-55"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb10-56"><a href="#cb10-56"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb10-57"><a href="#cb10-57"></a>  <span class="dt">tuneGrid=</span> xgb_grid3)</span>
<span id="cb10-58"><a href="#cb10-58"></a></span>
<span id="cb10-59"><a href="#cb10-59"></a><span class="co">## XGB4 ----</span></span>
<span id="cb10-60"><a href="#cb10-60"></a>xgb_grid4 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb10-61"><a href="#cb10-61"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">1250</span>),</span>
<span id="cb10-62"><a href="#cb10-62"></a>  <span class="dt">max_depth =</span> (<span class="dv">5</span>)<span class="op">*</span><span class="dv">2</span><span class="op">+</span><span class="dv">1</span>,</span>
<span id="cb10-63"><a href="#cb10-63"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>,<span class="fl">0.1</span>,<span class="fl">0.2</span>),</span>
<span id="cb10-64"><a href="#cb10-64"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.01</span>,<span class="fl">0.02</span>),</span>
<span id="cb10-65"><a href="#cb10-65"></a>  <span class="dt">colsample_bytree =</span> <span class="fl">0.75</span>,  </span>
<span id="cb10-66"><a href="#cb10-66"></a>  <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">10</span>),</span>
<span id="cb10-67"><a href="#cb10-67"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>,<span class="dv">1</span>))</span>
<span id="cb10-68"><a href="#cb10-68"></a></span>
<span id="cb10-69"><a href="#cb10-69"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb10-70"><a href="#cb10-70"></a>XGB_model4 &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb10-71"><a href="#cb10-71"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb10-72"><a href="#cb10-72"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb10-73"><a href="#cb10-73"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb10-74"><a href="#cb10-74"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb10-75"><a href="#cb10-75"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb10-76"><a href="#cb10-76"></a>  <span class="dt">tuneGrid=</span> xgb_grid4)</span>
<span id="cb10-77"><a href="#cb10-77"></a></span>
<span id="cb10-78"><a href="#cb10-78"></a><span class="co">## XGB5 ----</span></span>
<span id="cb10-79"><a href="#cb10-79"></a>xgb_grid5 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb10-80"><a href="#cb10-80"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">1500</span>,<span class="dv">1250</span>,<span class="dv">1000</span>,<span class="dv">750</span>,<span class="dv">500</span>),</span>
<span id="cb10-81"><a href="#cb10-81"></a>  <span class="dt">max_depth =</span> (<span class="dv">4</span><span class="op">:</span><span class="dv">5</span>)<span class="op">*</span><span class="dv">2</span><span class="op">+</span><span class="dv">1</span>,</span>
<span id="cb10-82"><a href="#cb10-82"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb10-83"><a href="#cb10-83"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb10-84"><a href="#cb10-84"></a>  <span class="dt">colsample_bytree =</span> <span class="fl">0.75</span>,  </span>
<span id="cb10-85"><a href="#cb10-85"></a>  <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">10</span>),</span>
<span id="cb10-86"><a href="#cb10-86"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="dv">1</span>))</span>
<span id="cb10-87"><a href="#cb10-87"></a></span>
<span id="cb10-88"><a href="#cb10-88"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb10-89"><a href="#cb10-89"></a>XGB_model5 &lt;-<span class="st">  </span>caret<span class="op">::</span><span class="kw">train</span>(</span>
<span id="cb10-90"><a href="#cb10-90"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb10-91"><a href="#cb10-91"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb10-92"><a href="#cb10-92"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb10-93"><a href="#cb10-93"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb10-94"><a href="#cb10-94"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb10-95"><a href="#cb10-95"></a>  <span class="dt">tuneGrid=</span> xgb_grid5)</span></code></pre></div>
<p><strong>Phase 2:</strong> After a little further reading, I understood <code>gamma</code> is ca. the pruning parameter, i.e.the minimum required improvement by a split, <code>eta</code> is the learning rate from tree-to-tree &amp; of which too-high values can easily result in over-fitting, <code>colsample_bytree</code> is randomly selecting a % of all variables based on which to fit a decision-tree, &amp; <code>subsample</code> is randomly sub-setting a % of observations from the given training data.</p>
<p>Armed with this knowledge I took a 2nd attempt at fitting few models with different parameters, looking to explore their effects. I read usually a <code>max_depth &lt;= 6</code> works fine, while I recalled Random Forests to have worked best with minimum observation nodes of ca. 15-25, &amp; were best-off with randomly selecting 1 variable based on which to split a node. I also wanted to relax gamma vis-a-vis previous models. So, in the below 6 models I explored the effects of gradually reducing <code>max_depth</code>s, &amp; <code>colsample_bytree</code>. I found XGB_7 to work best, improving my Kaggle AUC by 0.05%, to 0.71157, &amp; reducing colsample by tree all the way to 0.2 in XGB_11 over-fitted the model, yielding higher AUCs even on the validation set, but gradually worsening results on the test set.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="co">## XGB6 ----</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>xgb_grid6 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb11-3"><a href="#cb11-3"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">500</span>),</span>
<span id="cb11-4"><a href="#cb11-4"></a>  <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">4</span>)<span class="op">*</span><span class="dv">2</span><span class="op">+</span><span class="dv">1</span>,</span>
<span id="cb11-5"><a href="#cb11-5"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb11-6"><a href="#cb11-6"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.005</span>),</span>
<span id="cb11-7"><a href="#cb11-7"></a>  <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.8</span>,<span class="fl">0.9</span>),  </span>
<span id="cb11-8"><a href="#cb11-8"></a>  <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">10</span>,<span class="dv">20</span>),</span>
<span id="cb11-9"><a href="#cb11-9"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>,<span class="dv">1</span>))</span>
<span id="cb11-10"><a href="#cb11-10"></a></span>
<span id="cb11-11"><a href="#cb11-11"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb11-12"><a href="#cb11-12"></a>XGB_model6 &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb11-13"><a href="#cb11-13"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb11-14"><a href="#cb11-14"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb11-15"><a href="#cb11-15"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb11-16"><a href="#cb11-16"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb11-17"><a href="#cb11-17"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb11-18"><a href="#cb11-18"></a>  <span class="dt">tuneGrid=</span> xgb_grid6)</span>
<span id="cb11-19"><a href="#cb11-19"></a></span>
<span id="cb11-20"><a href="#cb11-20"></a>XGB_model6<span class="op">$</span>bestTune</span>
<span id="cb11-21"><a href="#cb11-21"></a>XGB_model6<span class="op">$</span>results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(ROC))</span>
<span id="cb11-22"><a href="#cb11-22"></a></span>
<span id="cb11-23"><a href="#cb11-23"></a>baseModels[[<span class="st">&quot;XGB_6&quot;</span>]] &lt;-<span class="st"> </span>XGB_model6</span>
<span id="cb11-24"><a href="#cb11-24"></a></span>
<span id="cb11-25"><a href="#cb11-25"></a><span class="co">## XGB7 ----</span></span>
<span id="cb11-26"><a href="#cb11-26"></a>xgb_grid7 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb11-27"><a href="#cb11-27"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">500</span>),</span>
<span id="cb11-28"><a href="#cb11-28"></a>  <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">11</span>,<span class="dv">9</span>), <span class="co">#*2+1,</span></span>
<span id="cb11-29"><a href="#cb11-29"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb11-30"><a href="#cb11-30"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.005</span>),</span>
<span id="cb11-31"><a href="#cb11-31"></a>  <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.6</span>,<span class="fl">0.75</span>),  </span>
<span id="cb11-32"><a href="#cb11-32"></a>  <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">10</span>,<span class="dv">20</span>),</span>
<span id="cb11-33"><a href="#cb11-33"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="fl">0.8</span>))</span>
<span id="cb11-34"><a href="#cb11-34"></a></span>
<span id="cb11-35"><a href="#cb11-35"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb11-36"><a href="#cb11-36"></a>XGB_model7 &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb11-37"><a href="#cb11-37"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb11-38"><a href="#cb11-38"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb11-39"><a href="#cb11-39"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb11-40"><a href="#cb11-40"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb11-41"><a href="#cb11-41"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb11-42"><a href="#cb11-42"></a>  <span class="dt">tuneGrid=</span> xgb_grid7)</span>
<span id="cb11-43"><a href="#cb11-43"></a></span>
<span id="cb11-44"><a href="#cb11-44"></a>XGB_model7<span class="op">$</span>bestTune</span>
<span id="cb11-45"><a href="#cb11-45"></a>XGB_model7<span class="op">$</span>results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(ROC))</span>
<span id="cb11-46"><a href="#cb11-46"></a></span>
<span id="cb11-47"><a href="#cb11-47"></a>baseModels[[<span class="st">&quot;XGB_7&quot;</span>]] &lt;-<span class="st"> </span>XGB_model7</span>
<span id="cb11-48"><a href="#cb11-48"></a></span>
<span id="cb11-49"><a href="#cb11-49"></a><span class="co">## XGB8 ----</span></span>
<span id="cb11-50"><a href="#cb11-50"></a>xgb_grid8 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb11-51"><a href="#cb11-51"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">500</span>),</span>
<span id="cb11-52"><a href="#cb11-52"></a>  <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">9</span>), <span class="co">#*2+1,</span></span>
<span id="cb11-53"><a href="#cb11-53"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb11-54"><a href="#cb11-54"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.005</span>),</span>
<span id="cb11-55"><a href="#cb11-55"></a>  <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.4</span>,<span class="fl">0.5</span>,<span class="fl">0.6</span>),  </span>
<span id="cb11-56"><a href="#cb11-56"></a>  <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">20</span>),</span>
<span id="cb11-57"><a href="#cb11-57"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>))</span>
<span id="cb11-58"><a href="#cb11-58"></a></span>
<span id="cb11-59"><a href="#cb11-59"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb11-60"><a href="#cb11-60"></a>XGB_model8 &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb11-61"><a href="#cb11-61"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb11-62"><a href="#cb11-62"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb11-63"><a href="#cb11-63"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb11-64"><a href="#cb11-64"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb11-65"><a href="#cb11-65"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb11-66"><a href="#cb11-66"></a>  <span class="dt">tuneGrid=</span> xgb_grid8)</span>
<span id="cb11-67"><a href="#cb11-67"></a></span>
<span id="cb11-68"><a href="#cb11-68"></a>XGB_model8<span class="op">$</span>bestTune</span>
<span id="cb11-69"><a href="#cb11-69"></a>XGB_model8<span class="op">$</span>results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(ROC))</span>
<span id="cb11-70"><a href="#cb11-70"></a></span>
<span id="cb11-71"><a href="#cb11-71"></a><span class="co">## XGB9 ----</span></span>
<span id="cb11-72"><a href="#cb11-72"></a>xgb_grid9 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb11-73"><a href="#cb11-73"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">500</span>,<span class="dv">350</span>),</span>
<span id="cb11-74"><a href="#cb11-74"></a>  <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">6</span>), <span class="co">#*2+1,</span></span>
<span id="cb11-75"><a href="#cb11-75"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb11-76"><a href="#cb11-76"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb11-77"><a href="#cb11-77"></a>  <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.3</span>,<span class="fl">0.4</span>),  </span>
<span id="cb11-78"><a href="#cb11-78"></a>  <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">20</span>,<span class="dv">30</span>),</span>
<span id="cb11-79"><a href="#cb11-79"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.7</span>,<span class="fl">0.8</span>))</span>
<span id="cb11-80"><a href="#cb11-80"></a></span>
<span id="cb11-81"><a href="#cb11-81"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb11-82"><a href="#cb11-82"></a>XGB_model9 &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb11-83"><a href="#cb11-83"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb11-84"><a href="#cb11-84"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb11-85"><a href="#cb11-85"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb11-86"><a href="#cb11-86"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb11-87"><a href="#cb11-87"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb11-88"><a href="#cb11-88"></a>  <span class="dt">tuneGrid=</span> xgb_grid9)</span>
<span id="cb11-89"><a href="#cb11-89"></a></span>
<span id="cb11-90"><a href="#cb11-90"></a>XGB_model9<span class="op">$</span>bestTune</span>
<span id="cb11-91"><a href="#cb11-91"></a>XGB_model9<span class="op">$</span>results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(ROC))</span>
<span id="cb11-92"><a href="#cb11-92"></a></span>
<span id="cb11-93"><a href="#cb11-93"></a><span class="co">## XGB10 ----</span></span>
<span id="cb11-94"><a href="#cb11-94"></a>xgb_grid10 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb11-95"><a href="#cb11-95"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">1000</span>,<span class="dv">500</span>),</span>
<span id="cb11-96"><a href="#cb11-96"></a>  <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">11</span>), <span class="co">#*2+1,</span></span>
<span id="cb11-97"><a href="#cb11-97"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb11-98"><a href="#cb11-98"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb11-99"><a href="#cb11-99"></a>  <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.2</span>,<span class="fl">0.3</span>),  </span>
<span id="cb11-100"><a href="#cb11-100"></a>  <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">20</span>),</span>
<span id="cb11-101"><a href="#cb11-101"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="dv">1</span>))</span>
<span id="cb11-102"><a href="#cb11-102"></a></span>
<span id="cb11-103"><a href="#cb11-103"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb11-104"><a href="#cb11-104"></a>XGB_model10 &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb11-105"><a href="#cb11-105"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb11-106"><a href="#cb11-106"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb11-107"><a href="#cb11-107"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb11-108"><a href="#cb11-108"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb11-109"><a href="#cb11-109"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb11-110"><a href="#cb11-110"></a>  <span class="dt">tuneGrid=</span> xgb_grid10)</span>
<span id="cb11-111"><a href="#cb11-111"></a></span>
<span id="cb11-112"><a href="#cb11-112"></a>XGB_model10<span class="op">$</span>bestTune</span>
<span id="cb11-113"><a href="#cb11-113"></a>XGB_model10<span class="op">$</span>results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(ROC))</span>
<span id="cb11-114"><a href="#cb11-114"></a></span>
<span id="cb11-115"><a href="#cb11-115"></a></span>
<span id="cb11-116"><a href="#cb11-116"></a><span class="co">## XGB11 ----</span></span>
<span id="cb11-117"><a href="#cb11-117"></a>xgb_grid11 &lt;-<span class="st">  </span><span class="kw">expand.grid</span>(</span>
<span id="cb11-118"><a href="#cb11-118"></a>  <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">2000</span>,<span class="dv">1750</span>,<span class="dv">1500</span>,<span class="dv">1250</span>,<span class="dv">1000</span>,<span class="dv">750</span>,<span class="dv">500</span>,<span class="dv">350</span>),</span>
<span id="cb11-119"><a href="#cb11-119"></a>  <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">6</span>), <span class="co">#*2+1,</span></span>
<span id="cb11-120"><a href="#cb11-120"></a>  <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb11-121"><a href="#cb11-121"></a>  <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb11-122"><a href="#cb11-122"></a>  <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.2</span>),  </span>
<span id="cb11-123"><a href="#cb11-123"></a>  <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">20</span>),</span>
<span id="cb11-124"><a href="#cb11-124"></a>  <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>))</span>
<span id="cb11-125"><a href="#cb11-125"></a></span>
<span id="cb11-126"><a href="#cb11-126"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb11-127"><a href="#cb11-127"></a>XGB_model11 &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb11-128"><a href="#cb11-128"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb11-129"><a href="#cb11-129"></a>  <span class="dt">data =</span> data_valid_n_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb11-130"><a href="#cb11-130"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb11-131"><a href="#cb11-131"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb11-132"><a href="#cb11-132"></a>  <span class="dt">trControl =</span> train_control,</span>
<span id="cb11-133"><a href="#cb11-133"></a>  <span class="dt">tuneGrid=</span> xgb_grid11)</span>
<span id="cb11-134"><a href="#cb11-134"></a></span>
<span id="cb11-135"><a href="#cb11-135"></a>XGB_model11<span class="op">$</span>bestTune</span>
<span id="cb11-136"><a href="#cb11-136"></a>XGB_model11<span class="op">$</span>results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(ROC))</span></code></pre></div>
<p><strong>Phase 3:</strong> At this point trying to further improve my score, I tried 1st increasing the training data to 90% &amp; 80%, which resulted in lower prediction scores. Then, I realised I wasnt doing 3-times repeated 10-fold cross-validation as I thought I would, as I specified the index argument in my 1st traincontrol object by using <code>createFolds()</code>, rather then <code>createMultiFolds()</code>. So, I re-specified my fold-indices as shown above, &amp; tried both 5-times repeated 5- &amp; 10-fold cross-validation on my few best XGBoost models.</p>
<p>As can be seen below, I again tried a few different values for <code>colsample_bytree</code> &amp; <code>subsample</code> however to no avail. XGB_7 was still the best model, &amp; yielded an AUC of 0.71778, good for 5th place in the competition at the time of this writing. I also found 5-time repeated 5-fold cross-validation yields better results vs 10x5, or 10x3 cross-validation, so I settled for that going forward.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a><span class="co">## XGB7_75 - 5x5 CV - 75-25 train-test split -----</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb12-3"><a href="#cb12-3"></a>XGB_model7_<span class="dv">75</span> &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb12-4"><a href="#cb12-4"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb12-5"><a href="#cb12-5"></a>  <span class="dt">data =</span> data_valid_n_train_<span class="dv">75</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id) ,</span>
<span id="cb12-6"><a href="#cb12-6"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb12-7"><a href="#cb12-7"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb12-8"><a href="#cb12-8"></a>  <span class="dt">trControl =</span> train_control_<span class="dv">5</span>_<span class="dv">5</span>,</span>
<span id="cb12-9"><a href="#cb12-9"></a>  <span class="dt">tuneGrid=</span> xgb_grid7)</span>
<span id="cb12-10"><a href="#cb12-10"></a></span>
<span id="cb12-11"><a href="#cb12-11"></a><span class="co">## XGB7_75a - 5x5 CV - 75-25 train-test split -----</span></span>
<span id="cb12-12"><a href="#cb12-12"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb12-13"><a href="#cb12-13"></a>XGB_model7_75a &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb12-14"><a href="#cb12-14"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb12-15"><a href="#cb12-15"></a>  <span class="dt">data =</span> training_data_<span class="dv">75</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id) ,</span>
<span id="cb12-16"><a href="#cb12-16"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb12-17"><a href="#cb12-17"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb12-18"><a href="#cb12-18"></a>  <span class="dt">trControl =</span> train_control_<span class="dv">5</span>_<span class="dv">5</span>,</span>
<span id="cb12-19"><a href="#cb12-19"></a>  <span class="dt">tuneGrid=</span> <span class="kw">expand.grid</span>(</span>
<span id="cb12-20"><a href="#cb12-20"></a>    <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">500</span>),</span>
<span id="cb12-21"><a href="#cb12-21"></a>    <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">9</span>), <span class="co">#*2+1,</span></span>
<span id="cb12-22"><a href="#cb12-22"></a>    <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb12-23"><a href="#cb12-23"></a>    <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.005</span>),</span>
<span id="cb12-24"><a href="#cb12-24"></a>    <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">0.6</span>),  </span>
<span id="cb12-25"><a href="#cb12-25"></a>    <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">20</span>),</span>
<span id="cb12-26"><a href="#cb12-26"></a>    <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>,<span class="fl">0.7</span>,<span class="fl">0.6</span>)))</span>
<span id="cb12-27"><a href="#cb12-27"></a></span>
<span id="cb12-28"><a href="#cb12-28"></a><span class="co">## XGB7_75b - 5x5 CV - 75-25 train-test split -----</span></span>
<span id="cb12-29"><a href="#cb12-29"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb12-30"><a href="#cb12-30"></a>XGB_model7_75b &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb12-31"><a href="#cb12-31"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb12-32"><a href="#cb12-32"></a>  <span class="dt">data =</span> training_data_<span class="dv">75</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id) ,</span>
<span id="cb12-33"><a href="#cb12-33"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb12-34"><a href="#cb12-34"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb12-35"><a href="#cb12-35"></a>  <span class="dt">trControl =</span> train_control_<span class="dv">5</span>_<span class="dv">5</span>,</span>
<span id="cb12-36"><a href="#cb12-36"></a>  <span class="dt">tuneGrid=</span> <span class="kw">expand.grid</span>(</span>
<span id="cb12-37"><a href="#cb12-37"></a>    <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">500</span>),</span>
<span id="cb12-38"><a href="#cb12-38"></a>    <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">9</span>), <span class="co">#*2+1,</span></span>
<span id="cb12-39"><a href="#cb12-39"></a>    <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb12-40"><a href="#cb12-40"></a>    <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.005</span>),</span>
<span id="cb12-41"><a href="#cb12-41"></a>    <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.6</span>),  </span>
<span id="cb12-42"><a href="#cb12-42"></a>    <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">20</span>),</span>
<span id="cb12-43"><a href="#cb12-43"></a>    <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>,<span class="fl">0.7</span>,<span class="fl">0.6</span>,<span class="fl">0.5</span>)))</span>
<span id="cb12-44"><a href="#cb12-44"></a></span>
<span id="cb12-45"><a href="#cb12-45"></a><span class="co">## XGB7_75 - 10x3 CV - 75-25 train-test split -----</span></span>
<span id="cb12-46"><a href="#cb12-46"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb12-47"><a href="#cb12-47"></a>XGB_model7_<span class="dv">75</span>_<span class="dv">10</span>_<span class="dv">3</span> &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb12-48"><a href="#cb12-48"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb12-49"><a href="#cb12-49"></a>  <span class="dt">data =</span> training_data_<span class="dv">75</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id) ,</span>
<span id="cb12-50"><a href="#cb12-50"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb12-51"><a href="#cb12-51"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb12-52"><a href="#cb12-52"></a>  <span class="dt">trControl =</span> train_control_<span class="dv">10</span>_<span class="dv">3</span>_<span class="dv">75</span>,</span>
<span id="cb12-53"><a href="#cb12-53"></a>  <span class="dt">tuneGrid=</span>  <span class="kw">expand.grid</span>(</span>
<span id="cb12-54"><a href="#cb12-54"></a>    <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">500</span>),</span>
<span id="cb12-55"><a href="#cb12-55"></a>    <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">11</span>,<span class="dv">9</span>), <span class="co">#*2+1,</span></span>
<span id="cb12-56"><a href="#cb12-56"></a>    <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.005</span>,<span class="fl">0.01</span>),</span>
<span id="cb12-57"><a href="#cb12-57"></a>    <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.005</span>),</span>
<span id="cb12-58"><a href="#cb12-58"></a>    <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.6</span>),  </span>
<span id="cb12-59"><a href="#cb12-59"></a>    <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">20</span>),</span>
<span id="cb12-60"><a href="#cb12-60"></a>    <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>)))</span>
<span id="cb12-61"><a href="#cb12-61"></a></span>
<span id="cb12-62"><a href="#cb12-62"></a><span class="co">## XGB8_75_5_5 ----</span></span>
<span id="cb12-63"><a href="#cb12-63"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb12-64"><a href="#cb12-64"></a>XGB_model8_<span class="dv">75</span>_<span class="dv">5</span>_<span class="dv">5</span> &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb12-65"><a href="#cb12-65"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb12-66"><a href="#cb12-66"></a>  <span class="dt">data =</span> training_data_<span class="dv">75</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb12-67"><a href="#cb12-67"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb12-68"><a href="#cb12-68"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb12-69"><a href="#cb12-69"></a>  <span class="dt">trControl =</span> train_control_<span class="dv">5</span>_<span class="dv">5</span>,</span>
<span id="cb12-70"><a href="#cb12-70"></a>  <span class="dt">tuneGrid=</span> xgb_grid8)</span>
<span id="cb12-71"><a href="#cb12-71"></a></span>
<span id="cb12-72"><a href="#cb12-72"></a><span class="co">## XGB11_75_5_5 ----</span></span>
<span id="cb12-73"><a href="#cb12-73"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb12-74"><a href="#cb12-74"></a>XGB_model11_<span class="dv">75</span>_<span class="dv">5</span>_<span class="dv">5</span> &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb12-75"><a href="#cb12-75"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb12-76"><a href="#cb12-76"></a>  <span class="dt">data =</span> training_data_<span class="dv">75</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id),</span>
<span id="cb12-77"><a href="#cb12-77"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb12-78"><a href="#cb12-78"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb12-79"><a href="#cb12-79"></a>  <span class="dt">trControl =</span> train_control_<span class="dv">5</span>_<span class="dv">5</span>,</span>
<span id="cb12-80"><a href="#cb12-80"></a>  <span class="dt">tuneGrid=</span> <span class="kw">expand.grid</span>(</span>
<span id="cb12-81"><a href="#cb12-81"></a>    <span class="dt">nrounds=</span><span class="kw">c</span>(<span class="dv">350</span>),</span>
<span id="cb12-82"><a href="#cb12-82"></a>    <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">6</span>), <span class="co">#*2+1,</span></span>
<span id="cb12-83"><a href="#cb12-83"></a>    <span class="dt">eta =</span> <span class="kw">c</span>(<span class="fl">0.01</span>),</span>
<span id="cb12-84"><a href="#cb12-84"></a>    <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.005</span>),</span>
<span id="cb12-85"><a href="#cb12-85"></a>    <span class="dt">colsample_bytree =</span> <span class="kw">c</span>(<span class="fl">0.3</span>,<span class="fl">0.4</span>,<span class="fl">0.5</span>),  </span>
<span id="cb12-86"><a href="#cb12-86"></a>    <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">20</span>),</span>
<span id="cb12-87"><a href="#cb12-87"></a>    <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.8</span>)))</span></code></pre></div>
<p><strong>Phase 4:</strong> At this point some friendly, competitiveness surfaced, while we developed a habit of comparing our results during the year already. 1 key takeaway from these discussions were that many competitors fitted their models to the complete training dataset. With no harm in trying, I did so too, again using my best models, but exploring a few different parameter values for <code>gamma</code> &amp; <code>min_child_weight</code>. This gave me an AUC of 0.71858, or a roughly 0.08% improvement.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="co">## XGB7_75 - 5x5 CV - fit to total training data -----</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb13-3"><a href="#cb13-3"></a>XGB_model7_<span class="dv">75</span>_full &lt;-<span class="st">  </span><span class="kw">train</span>(</span>
<span id="cb13-4"><a href="#cb13-4"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb13-5"><a href="#cb13-5"></a>  <span class="dt">data =</span> df_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>article_id) ,</span>
<span id="cb13-6"><a href="#cb13-6"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb13-7"><a href="#cb13-7"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb13-8"><a href="#cb13-8"></a>  <span class="dt">trControl =</span> <span class="kw">trainControl</span>(</span>
<span id="cb13-9"><a href="#cb13-9"></a>    <span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,<span class="dt">number =</span> <span class="dv">5</span>,<span class="dt">repeats =</span> <span class="dv">5</span>,</span>
<span id="cb13-10"><a href="#cb13-10"></a>    <span class="dt">verboseIter =</span> <span class="ot">TRUE</span>, <span class="dt">summaryFunction =</span> twoClassSummary, <span class="dt">classProbs =</span> T,</span>
<span id="cb13-11"><a href="#cb13-11"></a>    <span class="dt">allowParallel =</span> <span class="ot">TRUE</span>),</span>
<span id="cb13-12"><a href="#cb13-12"></a>  <span class="dt">tuneGrid=</span> <span class="kw">expand.grid</span>(</span>
<span id="cb13-13"><a href="#cb13-13"></a>    <span class="dt">nrounds =</span> <span class="dv">500</span>,</span>
<span id="cb13-14"><a href="#cb13-14"></a>    <span class="dt">max_depth =</span> <span class="dv">9</span>,</span>
<span id="cb13-15"><a href="#cb13-15"></a>    <span class="dt">eta =</span> <span class="fl">0.01</span>,</span>
<span id="cb13-16"><a href="#cb13-16"></a>    <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.005</span>,<span class="fl">0.001</span>),</span>
<span id="cb13-17"><a href="#cb13-17"></a>    <span class="dt">colsample_bytree =</span> <span class="fl">0.6</span>,</span>
<span id="cb13-18"><a href="#cb13-18"></a>    <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">20</span>),</span>
<span id="cb13-19"><a href="#cb13-19"></a>    <span class="dt">subsample =</span> <span class="fl">0.8</span>))</span></code></pre></div>
<p>The other key takeaway from in-class discussions was other including <code>article_id</code> in their explanatory variables, &amp; with improvement in the neighbourhood of 0.3%. At that point being about 0.25% below 1st place, &amp; no idea how else to improve my prediction scores, I figured why-not.</p>
<p>In effort to rationalize the decision to include articles IDs, one could argue a news platform generally grows over time, &amp; the number of visitors have a bearing on how popular an article is going to be, therefore later/more recent articles should have a tendency to be more famous then earlier ones, which can be captured by the <code>article_id</code> variable, assuming it is assigned to articles in an ordered fashion. Despite no proof whether article_ids are ordered, no such visible tendency from LOESS curves, &amp; a generally bas practice to include IDs as explanatory variables, I went ahead &amp; tried, again with a few different exact specifications as seen below.</p>
<p>To my suprise, this resulted in my currently leading public score, with an AUC of 0.7211, i.e.a 0.25% imrpovement over my previous model, that was also trainined on the full training dataset, with the same parameters. After finding the best-tuned model, I also ran it with 5x repeated 10-fold cross-validation, reaching slightly worse results. All in all, I found my final model.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a><span class="co">## XGB7_75 - 5x5 CV - fit to total training data inc. article -----</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>df_train<span class="op">$</span>article_id &lt;-<span class="st"> </span>df_train<span class="op">$</span>article_id <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.numeric</span>()</span>
<span id="cb14-3"><a href="#cb14-3"></a></span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb14-5"><a href="#cb14-5"></a>XGB_model7_<span class="dv">75</span>_full_art &lt;-<span class="st">  </span>caret<span class="op">::</span><span class="kw">train</span>(</span>
<span id="cb14-6"><a href="#cb14-6"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb14-7"><a href="#cb14-7"></a>  <span class="dt">data =</span> df_train,</span>
<span id="cb14-8"><a href="#cb14-8"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb14-9"><a href="#cb14-9"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb14-10"><a href="#cb14-10"></a>  <span class="dt">trControl =</span> <span class="kw">trainControl</span>(</span>
<span id="cb14-11"><a href="#cb14-11"></a>    <span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,<span class="dt">number =</span> <span class="dv">5</span>,<span class="dt">repeats =</span> <span class="dv">5</span>,</span>
<span id="cb14-12"><a href="#cb14-12"></a>    <span class="dt">verboseIter =</span> <span class="ot">TRUE</span>, <span class="dt">summaryFunction =</span> twoClassSummary, <span class="dt">classProbs =</span> T,</span>
<span id="cb14-13"><a href="#cb14-13"></a>    <span class="dt">allowParallel =</span> <span class="ot">TRUE</span>),</span>
<span id="cb14-14"><a href="#cb14-14"></a>  <span class="dt">tuneGrid=</span> <span class="kw">expand.grid</span>(</span>
<span id="cb14-15"><a href="#cb14-15"></a>    <span class="dt">nrounds =</span> <span class="dv">500</span>,</span>
<span id="cb14-16"><a href="#cb14-16"></a>    <span class="dt">max_depth =</span> <span class="dv">9</span>,</span>
<span id="cb14-17"><a href="#cb14-17"></a>    <span class="dt">eta =</span> <span class="fl">0.01</span>,</span>
<span id="cb14-18"><a href="#cb14-18"></a>    <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.005</span>,<span class="fl">0.001</span>),</span>
<span id="cb14-19"><a href="#cb14-19"></a>    <span class="dt">colsample_bytree =</span> <span class="fl">0.6</span>,</span>
<span id="cb14-20"><a href="#cb14-20"></a>    <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">20</span>),</span>
<span id="cb14-21"><a href="#cb14-21"></a>    <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.7</span>,<span class="fl">0.8</span>)))</span>
<span id="cb14-22"><a href="#cb14-22"></a></span>
<span id="cb14-23"><a href="#cb14-23"></a><span class="co">## XGB7_75 - 10x5 CV - fit to total training data inc. article -----</span></span>
<span id="cb14-24"><a href="#cb14-24"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb14-25"><a href="#cb14-25"></a>XGB_model7_10x5_full_art &lt;-<span class="st">  </span>caret<span class="op">::</span><span class="kw">train</span>(</span>
<span id="cb14-26"><a href="#cb14-26"></a>  is_popular <span class="op">~</span><span class="st"> </span>.,</span>
<span id="cb14-27"><a href="#cb14-27"></a>  <span class="dt">data =</span> df_train,</span>
<span id="cb14-28"><a href="#cb14-28"></a>  <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="co"># xgbDART / xgbLinear / xgbTree</span></span>
<span id="cb14-29"><a href="#cb14-29"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb14-30"><a href="#cb14-30"></a>  <span class="dt">trControl =</span> <span class="kw">trainControl</span>(</span>
<span id="cb14-31"><a href="#cb14-31"></a>    <span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,<span class="dt">number =</span> <span class="dv">10</span>,<span class="dt">repeats =</span> <span class="dv">5</span>,</span>
<span id="cb14-32"><a href="#cb14-32"></a>    <span class="dt">verboseIter =</span> <span class="ot">TRUE</span>, <span class="dt">summaryFunction =</span> twoClassSummary, <span class="dt">classProbs =</span> T,</span>
<span id="cb14-33"><a href="#cb14-33"></a>    <span class="dt">allowParallel =</span> <span class="ot">TRUE</span>),</span>
<span id="cb14-34"><a href="#cb14-34"></a>  <span class="dt">tuneGrid=</span> <span class="kw">expand.grid</span>(</span>
<span id="cb14-35"><a href="#cb14-35"></a>    <span class="dt">nrounds =</span> <span class="dv">500</span>,</span>
<span id="cb14-36"><a href="#cb14-36"></a>    <span class="dt">max_depth =</span> <span class="dv">9</span>,</span>
<span id="cb14-37"><a href="#cb14-37"></a>    <span class="dt">eta =</span> <span class="fl">0.01</span>,</span>
<span id="cb14-38"><a href="#cb14-38"></a>    <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="fl">0.001</span>),</span>
<span id="cb14-39"><a href="#cb14-39"></a>    <span class="dt">colsample_bytree =</span> <span class="fl">0.6</span>,</span>
<span id="cb14-40"><a href="#cb14-40"></a>    <span class="dt">min_child_weight =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">20</span>),</span>
<span id="cb14-41"><a href="#cb14-41"></a>    <span class="dt">subsample =</span> <span class="kw">c</span>(<span class="fl">0.7</span>)))</span></code></pre></div>
</div>
<div id="neural-nets" class="section level2">
<h2><span class="header-section-number">4.5</span> Neural Nets</h2>
<p>To predict new article popularity, I used both the Keras-approach learned recently, as well as the <code>caret::train()</code> approach, using the <code>&quot;nnet&quot;</code> method. <code>caret</code>s <code>nnet</code> method allows 2 parameters, <code>size</code> i.e.the number of neurons, &amp; <code>decay</code>, equivalent/similar to dropout rates in the <code>keras</code> framework. Running the model with 75% of the training data, with 5x5 repeated cross-validation, yielded 0.69974 AUC in the best of cases.</p>
<p>I also applied dense neural nets using <code>keras</code> after appropriate transformations as shown below. I 1st used a for loop to scael each columns values to between 0-1, by adding to each column vector its minimums absolute value, than dividing the resulting vector by the resulting vectors maximum value. I converted the outcome variables to dummy variable table using <code>to_categorical()</code> &amp; sampled 20000 observations as training data, using the remaining observations as the validation set. After fitting a 3-layer neural net through 1000 epochs, the fit history showed no improvement (or any change in validation accuracy) whatsoever, perhaps indicating neural nets not to be a suitable approach for the problem at hand. The <code>keras</code> approach also yielded AUC results of 0.69 in the best case.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="co"># NNet ----</span></span>
<span id="cb15-2"><a href="#cb15-2"></a>nnet_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(</span>
<span id="cb15-3"><a href="#cb15-3"></a>  <span class="dt">size =</span> <span class="dv">3</span><span class="op">:</span><span class="dv">7</span>,</span>
<span id="cb15-4"><a href="#cb15-4"></a>  <span class="dt">decay =</span> <span class="kw">seq</span>(<span class="fl">4.5</span>,<span class="fl">6.5</span>,<span class="dt">by=</span><span class="fl">0.2</span>))</span>
<span id="cb15-5"><a href="#cb15-5"></a></span>
<span id="cb15-6"><a href="#cb15-6"></a><span class="kw">set.seed</span>(<span class="dv">123456789</span>)</span>
<span id="cb15-7"><a href="#cb15-7"></a>nnet_model &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">train</span>(</span>
<span id="cb15-8"><a href="#cb15-8"></a><span class="co">#  is_popular ~ .,</span></span>
<span id="cb15-9"><a href="#cb15-9"></a>  <span class="dt">method =</span> <span class="st">&quot;nnet&quot;</span>,</span>
<span id="cb15-10"><a href="#cb15-10"></a>  <span class="dt">x =</span> training_data_<span class="dv">75</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span><span class="kw">c</span>(article_id,is_popular)),</span>
<span id="cb15-11"><a href="#cb15-11"></a>  <span class="dt">y =</span> training_data_<span class="dv">75</span><span class="op">$</span>is_popular,</span>
<span id="cb15-12"><a href="#cb15-12"></a>  <span class="dt">trControl =</span> train_control_<span class="dv">5</span>_<span class="dv">5</span>,</span>
<span id="cb15-13"><a href="#cb15-13"></a>  <span class="dt">tuneGrid =</span> nnet_grid,</span>
<span id="cb15-14"><a href="#cb15-14"></a>  <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>, <span class="st">&quot;pca&quot;</span>),</span>
<span id="cb15-15"><a href="#cb15-15"></a>    <span class="co"># decay: regularization, has to center and scale like with Ridge, Lasso</span></span>
<span id="cb15-16"><a href="#cb15-16"></a>    <span class="co"># PCA: correlated variables are problematic for gradient-based optimization</span></span>
<span id="cb15-17"><a href="#cb15-17"></a>  <span class="dt">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb15-18"><a href="#cb15-18"></a>  <span class="co"># avoid extensive iteration output</span></span>
<span id="cb15-19"><a href="#cb15-19"></a>  <span class="dt">trace =</span> <span class="ot">FALSE</span></span>
<span id="cb15-20"><a href="#cb15-20"></a>)</span>
<span id="cb15-21"><a href="#cb15-21"></a></span>
<span id="cb15-22"><a href="#cb15-22"></a><span class="co"># Keras Version ----</span></span>
<span id="cb15-23"><a href="#cb15-23"></a><span class="kw">library</span>(keras)</span>
<span id="cb15-24"><a href="#cb15-24"></a><span class="kw">library</span>(tensorflow)</span>
<span id="cb15-25"><a href="#cb15-25"></a></span>
<span id="cb15-26"><a href="#cb15-26"></a><span class="co"># Regularize datasets</span></span>
<span id="cb15-27"><a href="#cb15-27"></a>  <span class="co"># add minimum -&gt; divide by maximum </span></span>
<span id="cb15-28"><a href="#cb15-28"></a>df_train_nn &lt;-<span class="st"> </span><span class="kw">select</span>(df_train,<span class="op">-</span><span class="kw">c</span>( is_popular))</span>
<span id="cb15-29"><a href="#cb15-29"></a></span>
<span id="cb15-30"><a href="#cb15-30"></a><span class="cf">for</span> (i  <span class="cf">in</span> <span class="kw">colnames</span>(df_train_nn)) {</span>
<span id="cb15-31"><a href="#cb15-31"></a>  col &lt;-<span class="st"> </span>df_train_nn[,<span class="kw">c</span>(i)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb15-32"><a href="#cb15-32"></a>  col2 &lt;-<span class="st"> </span>col <span class="op">+</span><span class="st"> </span><span class="kw">abs</span>(<span class="kw">min</span>(col))</span>
<span id="cb15-33"><a href="#cb15-33"></a>  col3 &lt;-<span class="st"> </span>col2 <span class="op">/</span><span class="st"> </span><span class="kw">max</span>(col2)</span>
<span id="cb15-34"><a href="#cb15-34"></a>  df_train_nn[,<span class="kw">c</span>(i)] &lt;-<span class="st"> </span>col3</span>
<span id="cb15-35"><a href="#cb15-35"></a>}</span>
<span id="cb15-36"><a href="#cb15-36"></a></span>
<span id="cb15-37"><a href="#cb15-37"></a>df_train_nn</span>
<span id="cb15-38"><a href="#cb15-38"></a></span>
<span id="cb15-39"><a href="#cb15-39"></a>df_train_keras &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(df_train_nn)</span>
<span id="cb15-40"><a href="#cb15-40"></a>df_train_keras_y &lt;-<span class="st"> </span><span class="kw">ifelse</span>(df_train<span class="op">$</span>is_popular <span class="op">==</span><span class="st"> &quot;Yes&quot;</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb15-41"><a href="#cb15-41"></a>df_train_keras_y &lt;-<span class="st"> </span><span class="kw">to_categorical</span>(<span class="kw">as.numeric</span>(df_train<span class="op">$</span>is_popular)<span class="op">-</span><span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb15-42"><a href="#cb15-42"></a></span>
<span id="cb15-43"><a href="#cb15-43"></a>trainindices &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">seq</span>(<span class="kw">nrow</span>(df_train_keras)), <span class="dv">20000</span>)</span>
<span id="cb15-44"><a href="#cb15-44"></a></span>
<span id="cb15-45"><a href="#cb15-45"></a>df_train_<span class="dv">4</span>_nn &lt;-<span class="st">  </span>df_train_keras[trainindices,]</span>
<span id="cb15-46"><a href="#cb15-46"></a>df_valid_<span class="dv">4</span>_nn &lt;-<span class="st">  </span>df_train_keras[<span class="op">-</span>trainindices,]</span>
<span id="cb15-47"><a href="#cb15-47"></a>df_train_<span class="dv">4</span>_nn_y &lt;-<span class="st"> </span>df_train_keras_y[trainindices,]</span>
<span id="cb15-48"><a href="#cb15-48"></a>df_valid_<span class="dv">4</span>_nn_y &lt;-<span class="st"> </span>df_train_keras_y[<span class="op">-</span>trainindices,]</span>
<span id="cb15-49"><a href="#cb15-49"></a></span>
<span id="cb15-50"><a href="#cb15-50"></a>df_test_nn &lt;-<span class="st"> </span><span class="kw">Df_Transforms</span>(<span class="kw">select</span>(df_test,<span class="op">-</span><span class="kw">c</span>(article_id)))</span>
<span id="cb15-51"><a href="#cb15-51"></a><span class="cf">for</span> (i  <span class="cf">in</span> <span class="kw">colnames</span>(df_test_nn)) {</span>
<span id="cb15-52"><a href="#cb15-52"></a>  col &lt;-<span class="st"> </span>df_test_nn[,<span class="kw">c</span>(i)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.data.frame</span>()</span>
<span id="cb15-53"><a href="#cb15-53"></a>  col2 &lt;-<span class="st"> </span>col <span class="op">+</span><span class="st"> </span><span class="kw">abs</span>(<span class="kw">min</span>(col))</span>
<span id="cb15-54"><a href="#cb15-54"></a>  col3 &lt;-<span class="st"> </span>col2 <span class="op">/</span><span class="st"> </span><span class="kw">max</span>(col2)</span>
<span id="cb15-55"><a href="#cb15-55"></a>  df_test_nn[,<span class="kw">c</span>(i)] &lt;-<span class="st"> </span>col3</span>
<span id="cb15-56"><a href="#cb15-56"></a>}</span>
<span id="cb15-57"><a href="#cb15-57"></a></span>
<span id="cb15-58"><a href="#cb15-58"></a>df_test_keras &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(df_test_nn)</span>
<span id="cb15-59"><a href="#cb15-59"></a>df_test_articles &lt;-<span class="st"> </span>df_test<span class="op">$</span>article_id</span>
<span id="cb15-60"><a href="#cb15-60"></a></span>
<span id="cb15-61"><a href="#cb15-61"></a><span class="co"># Network design</span></span>
<span id="cb15-62"><a href="#cb15-62"></a>model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>()</span>
<span id="cb15-63"><a href="#cb15-63"></a>model <span class="op">%&gt;%</span></span>
<span id="cb15-64"><a href="#cb15-64"></a><span class="st">  </span><span class="co"># Input layer</span></span>
<span id="cb15-65"><a href="#cb15-65"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="dt">input_shape =</span>  <span class="kw">ncol</span>(df_train_keras)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-66"><a href="#cb15-66"></a><span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.2</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-67"><a href="#cb15-67"></a><span class="st">  </span><span class="co"># Hidden layer</span></span>
<span id="cb15-68"><a href="#cb15-68"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">16</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb15-69"><a href="#cb15-69"></a><span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.2</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-70"><a href="#cb15-70"></a><span class="st">  </span></span>
<span id="cb15-71"><a href="#cb15-71"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">8</span>, <span class="dt">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb15-72"><a href="#cb15-72"></a><span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.2</span>) <span class="op">%&gt;%</span></span>
<span id="cb15-73"><a href="#cb15-73"></a><span class="st">  </span></span>
<span id="cb15-74"><a href="#cb15-74"></a><span class="st">  </span><span class="co"># Output layer</span></span>
<span id="cb15-75"><a href="#cb15-75"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">2</span>, <span class="dt">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb15-76"><a href="#cb15-76"></a></span>
<span id="cb15-77"><a href="#cb15-77"></a><span class="co"># Network config</span></span>
<span id="cb15-78"><a href="#cb15-78"></a><span class="co">#history &lt;-</span></span>
<span id="cb15-79"><a href="#cb15-79"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(<span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>,</span>
<span id="cb15-80"><a href="#cb15-80"></a>  <span class="dt">optimizer =</span> <span class="kw">optimizer_rmsprop</span>(),<span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">&quot;accuracy&quot;</span>))</span>
<span id="cb15-81"><a href="#cb15-81"></a></span>
<span id="cb15-82"><a href="#cb15-82"></a><span class="co"># Running our data</span></span>
<span id="cb15-83"><a href="#cb15-83"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(</span>
<span id="cb15-84"><a href="#cb15-84"></a>  df_train_<span class="dv">4</span>_nn, df_train_<span class="dv">4</span>_nn_y, </span>
<span id="cb15-85"><a href="#cb15-85"></a>  <span class="dt">epochs =</span> <span class="dv">1000</span>, </span>
<span id="cb15-86"><a href="#cb15-86"></a>  <span class="dt">batch_size =</span> <span class="dv">500</span>,</span>
<span id="cb15-87"><a href="#cb15-87"></a>  <span class="dt">validation_data =</span> <span class="kw">list</span>(df_valid_<span class="dv">4</span>_nn,df_valid_<span class="dv">4</span>_nn_y)</span>
<span id="cb15-88"><a href="#cb15-88"></a>)</span>
<span id="cb15-89"><a href="#cb15-89"></a></span>
<span id="cb15-90"><a href="#cb15-90"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">preds =</span> model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict_proba</span>(df_valid_<span class="dv">4</span>_nn),</span>
<span id="cb15-91"><a href="#cb15-91"></a>                 <span class="dt">ref =</span> <span class="kw">as.numeric</span>(df_train<span class="op">$</span>is_popular[<span class="op">-</span>trainindices])<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb15-92"><a href="#cb15-92"></a></span>
<span id="cb15-93"><a href="#cb15-93"></a>auc &lt;-<span class="st"> </span>pROC<span class="op">::</span><span class="kw">roc</span>(df<span class="op">$</span>ref,df<span class="op">$</span>preds<span class="fl">.1</span> )<span class="op">$</span>auc <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">4</span>)</span>
<span id="cb15-94"><a href="#cb15-94"></a></span>
<span id="cb15-95"><a href="#cb15-95"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict_proba</span>(df_train_<span class="dv">4</span>_nn)</span>
<span id="cb15-96"><a href="#cb15-96"></a></span>
<span id="cb15-97"><a href="#cb15-97"></a><span class="kw">data.frame</span>(<span class="dt">article_id =</span> df_test<span class="op">$</span>article_id,<span class="dt">score =</span> <span class="kw">predict_proba</span>(model,df_test_keras)[,<span class="dv">1</span>]) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-98"><a href="#cb15-98"></a><span class="st">  </span><span class="kw">write_csv</span>(<span class="st">&quot;Keras1.csv&quot;</span>)</span></code></pre></div>
</div>
</div>
<div id="lessons-learned" class="section level1">
<h1><span class="header-section-number">5</span> Lessons Learned</h1>
<p>Throughout doing this competition, a number of key lessons emerged to take away for future competitions. As it very well may be that Kaggle would serve as the platform to explore &amp; implement newly learned concepts, or refresh old ones by participating in external competitions, it may be useful for readers with similar outlooks.</p>
<p><strong>Storing Models:</strong> After the 2nd batch of XGBoost models I made the mistake of re-running my model with different tuning parameters in hopes of improving my results. Before, I knew it, I lost my model, &amp; with it about 12 hours to eventually re-create it again. I could have easily avoided this by establishing &amp; storing a named model list earlier in the process (the same named model list you could pass to the helper functions defined above, or the <code>caret::resamples()</code> function to compare models whom were optimized with the same number of folds). Once having such a named model list, assigning new models is easy, just as stroing &amp; reading in said list:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>baseModels &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;Enet&quot;</span> =<span class="st"> </span>Benchmark_GLM,</span>
<span id="cb16-2"><a href="#cb16-2"></a>                  <span class="st">&quot;RF_80p&quot;</span> =<span class="st"> </span>RF_model_ReFit_<span class="dv">2</span>,</span>
<span id="cb16-3"><a href="#cb16-3"></a>                   <span class="st">&quot;GBM_1&quot;</span> =<span class="st"> </span>GBM_model_<span class="dv">1</span>,</span>
<span id="cb16-4"><a href="#cb16-4"></a>                   <span class="st">&quot;GBM_2&quot;</span> =<span class="st"> </span>GBM_model_<span class="dv">2</span>,</span>
<span id="cb16-5"><a href="#cb16-5"></a>                   <span class="st">&quot;XGB_1&quot;</span> =<span class="st"> </span>XGB_model,</span>
<span id="cb16-6"><a href="#cb16-6"></a>                   <span class="st">&quot;XGB_2&quot;</span> =<span class="st"> </span>XGB_model2,</span>
<span id="cb16-7"><a href="#cb16-7"></a>                   <span class="st">&quot;XGB_3&quot;</span> =<span class="st"> </span>XGB_model3,</span>
<span id="cb16-8"><a href="#cb16-8"></a>                   <span class="st">&quot;XGB_4&quot;</span> =<span class="st"> </span>XGB_model4,</span>
<span id="cb16-9"><a href="#cb16-9"></a>                   <span class="st">&quot;XGB_5&quot;</span> =<span class="st"> </span>XGB_model5,</span>
<span id="cb16-10"><a href="#cb16-10"></a>                   <span class="st">&quot;XGB_6&quot;</span> =<span class="st"> </span>XGB_model6,</span>
<span id="cb16-11"><a href="#cb16-11"></a>                   <span class="st">&quot;XGB_7&quot;</span> =<span class="st"> </span>XGB_model7,</span>
<span id="cb16-12"><a href="#cb16-12"></a>                   <span class="st">&quot;XGB_7a&quot;</span> =<span class="st"> </span>XGB_model7a,</span>
<span id="cb16-13"><a href="#cb16-13"></a>                   <span class="st">&quot;XGB_8&quot;</span> =<span class="st"> </span>XGB_model8,</span>
<span id="cb16-14"><a href="#cb16-14"></a>                   <span class="st">&quot;XGB_9&quot;</span> =<span class="st"> </span>XGB_model9,</span>
<span id="cb16-15"><a href="#cb16-15"></a>                   <span class="st">&quot;XGB_10&quot;</span> =<span class="st"> </span>XGB_model10,</span>
<span id="cb16-16"><a href="#cb16-16"></a>                   <span class="st">&quot;XGB_11&quot;</span> =<span class="st"> </span>XGB_model11</span>
<span id="cb16-17"><a href="#cb16-17"></a>)</span>
<span id="cb16-18"><a href="#cb16-18"></a></span>
<span id="cb16-19"><a href="#cb16-19"></a><span class="co"># To add e.g. the final best model:</span></span>
<span id="cb16-20"><a href="#cb16-20"></a>baseModels[[<span class="st">&#39;XGB7_5_5_100_art&#39;</span>]] &lt;-<span class="st"> </span>XGB_model7_<span class="dv">75</span>_full_art</span>
<span id="cb16-21"><a href="#cb16-21"></a></span>
<span id="cb16-22"><a href="#cb16-22"></a><span class="co"># Set working directory to save the named model list</span></span>
<span id="cb16-23"><a href="#cb16-23"></a><span class="kw">setwd</span>(<span class="st">&quot;C:/Users/helme/Desktop/CEU/WINTER_Term/Data_Science/Machine_Learning_Courses_DS1-3/DS2/Kaggle/Model_Objects&quot;</span>)</span>
<span id="cb16-24"><a href="#cb16-24"></a></span>
<span id="cb16-25"><a href="#cb16-25"></a><span class="co"># Give a nice descriptive name + todays date &amp; time for for-sure uniqueness</span></span>
<span id="cb16-26"><a href="#cb16-26"></a>baseModels_name &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;-|:&quot;</span>,<span class="st">&quot;_&quot;</span>,<span class="kw">paste0</span>(<span class="st">&quot;All_Current_Models_&quot;</span>,<span class="kw">Sys.Date</span>(),</span>
<span id="cb16-27"><a href="#cb16-27"></a>                          <span class="st">&quot;_&quot;</span>,<span class="kw">unlist</span>(<span class="kw">str_split</span>(<span class="kw">Sys.time</span>(),<span class="st">&quot; &quot;</span>))[<span class="dv">2</span>] ,<span class="st">&quot;.rds&quot;</span>))</span>
<span id="cb16-28"><a href="#cb16-28"></a><span class="kw">saveRDS</span>(baseModels,baseModels_name)</span>
<span id="cb16-29"><a href="#cb16-29"></a></span>
<span id="cb16-30"><a href="#cb16-30"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">names</span>(baseModels)) {</span>
<span id="cb16-31"><a href="#cb16-31"></a>  modelname &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;-|:&quot;</span>,<span class="st">&quot;_&quot;</span>,</span>
<span id="cb16-32"><a href="#cb16-32"></a>                    <span class="kw">paste0</span>(i,<span class="st">&quot;_&quot;</span>,<span class="kw">Sys.Date</span>(),</span>
<span id="cb16-33"><a href="#cb16-33"></a>                           <span class="st">&quot;_&quot;</span>,<span class="kw">unlist</span>(<span class="kw">str_split</span>(<span class="kw">Sys.time</span>(),<span class="st">&quot; &quot;</span>))[<span class="dv">2</span>],<span class="st">&quot;.rds&quot;</span>))</span>
<span id="cb16-34"><a href="#cb16-34"></a>  </span>
<span id="cb16-35"><a href="#cb16-35"></a>  <span class="kw">saveRDS</span>(baseModels[[i]],modelname)</span>
<span id="cb16-36"><a href="#cb16-36"></a>}</span>
<span id="cb16-37"><a href="#cb16-37"></a></span>
<span id="cb16-38"><a href="#cb16-38"></a><span class="co"># Download &amp; Read in e.g. most recent version - e.g. final best model</span></span>
<span id="cb16-39"><a href="#cb16-39"></a>GithubRDS_Folder &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/BrunoHelmeczy/Machine_Learning_Courses_DS1-3/main/DS2/Kaggle/Model_Objects&quot;</span></span>
<span id="cb16-40"><a href="#cb16-40"></a></span>
<span id="cb16-41"><a href="#cb16-41"></a><span class="kw">download.file</span>(<span class="kw">paste0</span>(GithubRDS_Folder,<span class="st">&quot;XGB7_5_5_100_art_2021_04_11_19_28_47.rds&quot;</span>),</span>
<span id="cb16-42"><a href="#cb16-42"></a><span class="st">&quot;XGB7_5_5_100_art.rds&quot;</span>, <span class="dt">method =</span> <span class="st">&quot;curl&quot;</span>)</span>
<span id="cb16-43"><a href="#cb16-43"></a>XGB7_<span class="dv">5</span>_<span class="dv">5</span>_<span class="dv">100</span>_art &lt;-<span class="st"> </span><span class="kw">readRDS</span>(<span class="st">&quot;XGB7_5_5_100_art.rds&quot;</span>)</span></code></pre></div>
<p><strong>createMultiFolds:</strong> As mentioned, after my 1st few rounds of modelling, I realized I used <code>createFolds()</code> rather then <code>createMultiFolds()</code>, to specify the row indices for any given fold of either repeat. One would most obviously use the <code>index</code> argument of <code>trainControl()</code> when looking to stack caret model objects, since its a pre-requisite both for <code>caretStack()</code> &amp; <code>caretEnsemble()</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a>MyFolds &lt;-<span class="st"> </span><span class="kw">createFolds</span>(data_valid_n_train<span class="op">$</span>is_popular, <span class="dt">k =</span> <span class="dv">10</span>)</span>
<span id="cb17-2"><a href="#cb17-2"></a>MyFolds_10x3 &lt;-<span class="st"> </span><span class="kw">createMultiFolds</span>(data_valid_n_train<span class="op">$</span>is_popular, <span class="dt">k =</span> <span class="dv">10</span>, <span class="dt">times =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><strong>Model tune length &amp; Parallel Processing:</strong> As shown above, a cluster can be registered when training caret model objects, &amp; thus parallel processing can easily be implemented. However, the key message I believe was the superiority in defining much smaller tuning grids, evaluating the results, &amp; deciding on the next grid based on that. Alternatively, e.g.by defining 108 long tuning grid, with 5x5 repeated cross-validation for a XGboost model can easily result in 16 hour runtime, especially with 9-11 maximum tree depth. Additionally, it may have been my fault somehow, but no training log is printed when parallel processing is implemented, so I didnt have any idea how long would a model still have to train to finish.</p>
<p><strong>Using all Training Data:</strong> Initially, I split my dataset into training, validation &amp; test data sets, thinking for example to fit base models on the 40% training data &amp; validate it on 30%, then use this 70% to re-fit all base models &amp; a stacked ensemble on top, checking its performance on the remaining 30% before submission. Another benefit was model training faster in the beginning, while gradually adding data improved test results, &amp; I would most likely avoid over-fitting the training &amp; test data, especially in the beginning when the models themselves arent well-calibrated. It turned out that if 1 would like to split the data to train-validation sets, a 75-25 split yielded highest accuracy results. However, using all available training data to re-fit a final best model improves results, in my case from AUC 0.71778 to 0.71867, i.e.0.09%.</p>
<p><code>article_id</code> <strong>:</strong> Finally, a significant &amp; somewhat unexpected &amp; irrational source of improvement proved to be adding in the <code>article_id</code> variable. As aforementioned under XGBoost modelling, it improved my results by ca. 0.25% AUC, giving me the final push to head the public leaderboard ca. 6 hours before the competition closes.</p>
</div>
<div id="conclusion" class="section level1">
<h1><span class="header-section-number">6</span> Conclusion</h1>
<p>This report summarized my efforts to win the in-house Kaggle competition hosted for the Data Science 2: Machine Learning Tools course held as part of the MSc Business Analytics program at the Central European University. As of writing these lines, my final best model leads the competitions public leaderboard with an AUC of 0.7211. This is an XGBoost model, using all available training data &amp; its variables, with parameters <code>nrounds = 500</code> i.e.number of trees, <code>max_depth = 9</code> maximum number of trees built on top of each other,<code>eta = 0.01</code> i.e.the learning rate from tree-to-tree, <code>gamma = 0.001</code> i.e.the pruning parameter, <code>colsample_bytree = 0.6</code> i.e.60% of variables are randomly selected for each of the 500 trees from which a decision-tree is to be built, <code>min_child_weight = 10</code> i.e.the minimum number of observations needed at a leaf-node to be able to make a split &amp; <code>subsample = 0.8</code> i.e.80% of observations are randomly selected to build the model. Project artifacts are all available on my GitHub ( <a href="https://github.com/BrunoHelmeczy/Machine_Learning_Courses_DS1-3/tree/main/DS2/Kaggle">here</a> ).</p>
</div>
</section>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
